<!-- 
RSS generated by JIRA (9.12.27#9120027-sha1:edc4490121e366e9e7bd2213d532dbe7e028fc5d) at Tue Sep 30 18:20:47 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>Java Bug System</title>
    <link>https://bugs.openjdk.org</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-us</language>    <build-info>
        <version>9.12.27</version>
        <build-number>9120027</build-number>
        <build-date>02-09-2025</build-date>
    </build-info>


<item>
            <title>[JDK-8305625] Stress test crashes with SEGV in Deoptimization::deoptimize_frame_internal(JavaThread*, long*, Deoptimization::DeoptReason)</title>
                <link>https://bugs.openjdk.org/browse/JDK-8305625</link>
                <project id="10100" key="JDK">JDK</project>
                    <description>Test crashes with &lt;br/&gt;
#&lt;br/&gt;
# A fatal error has been detected by the Java Runtime Environment:&lt;br/&gt;
#&lt;br/&gt;
#  SIGSEGV (0xb) at pc=0x00007f43c4b81577, pid=3145843, tid=3145853&lt;br/&gt;
#&lt;br/&gt;
# JRE version: Java(TM) SE Runtime Environment (21.0+15) (build 21-ea+15-LTS-1201)&lt;br/&gt;
# Java VM: Java HotSpot(TM) 64-Bit Server VM (21-ea+15-LTS-1201, mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, linux-amd64)&lt;br/&gt;
# Problematic frame:&lt;br/&gt;
# V  [libjvm.so+0x684577]  Deoptimization::deoptimize_frame_internal(JavaThread*, long*, Deoptimization::DeoptReason)+0x2e7&lt;br/&gt;
&lt;br/&gt;
..&lt;br/&gt;
Current thread (0x00007f43bc137430):  VMThread &amp;quot;VM Thread&amp;quot; [stack: 0x00007f43c01d5000,0x00007f43c02d5000] [id=3145853]&lt;br/&gt;
&lt;br/&gt;
Stack: [0x00007f43c01d5000,0x00007f43c02d5000],  sp=0x00007f43c02d25f0,  free space=1013k&lt;br/&gt;
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)&lt;br/&gt;
V  [libjvm.so+0x684577]  Deoptimization::deoptimize_frame_internal(JavaThread*, long*, Deoptimization::DeoptReason)+0x2e7  (frame_x86.inline.hpp:244)&lt;br/&gt;
V  [libjvm.so+0xf18165]  VM_Operation::evaluate()+0x105  (vmOperations.cpp:71)&lt;br/&gt;
V  [libjvm.so+0xf1a878]  VMThread::evaluate_operation(VM_Operation*)+0x278  (vmThread.cpp:281)&lt;br/&gt;
V  [libjvm.so+0xf1b347]  VMThread::inner_execute(VM_Operation*)+0x3a7  (vmThread.cpp:428)&lt;br/&gt;
V  [libjvm.so+0xf1b5f7]  VMThread::run()+0xb7  (vmThread.cpp:495)&lt;br/&gt;
V  [libjvm.so+0xe85a96]  Thread::call_run()+0xa6  (thread.cpp:224)&lt;br/&gt;
V  [libjvm.so+0xcaebf8]  thread_native_entry(Thread*)+0xd8  (os_linux.cpp:740)&lt;br/&gt;
&lt;br/&gt;
siginfo: si_signo: 11 (SIGSEGV), si_code: 1 (SEGV_MAPERR), si_addr: 0x0000000000000008&lt;br/&gt;
&lt;br/&gt;
Registers:&lt;br/&gt;
RAX=0x0000000000000000, RBX=0x00007f4308b59510, RCX=0x00007f43ac1f6f80, RDX=0x0000000000000000&lt;br/&gt;
RSP=0x00007f43c02d25f0, RBP=0x00007f43c02d3950, RSI=0x00007f43c02d2660, RDI=0x0000000000000000&lt;br/&gt;
R8 =0x00007f43ac1dab90, R9 =0x00007f43ac1dab80, R10=0x00007f43c634c000, R11=0x0000000000000000&lt;br/&gt;
R12=0x00007f43c02d2660, R13=0x00007f43c02d2620, R14=0x00007f43c02d26a0, R15=0x00007f42505357a0&lt;br/&gt;
RIP=0x00007f43c4b81577, EFLAGS=0x0000000000010283, CSGSFS=0x002b000000000033, ERR=0x0000000000000004&lt;br/&gt;
&amp;nbsp;&amp;nbsp;TRAPNO=0x000000000000000e&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
Register to memory mapping:&lt;br/&gt;
&lt;br/&gt;
RAX=0x0 is nullptr&lt;br/&gt;
RBX=0x00007f4308b59510 is pointing into the stack for thread: 0x00007f42505357a0&lt;br/&gt;
RCX=0x00007f43ac1f6f80 is pointing into interpreter code (not bytecode specific)&lt;br/&gt;
RDX=0x0 is nullptr&lt;br/&gt;
RSP=0x00007f43c02d25f0 points into unknown readable memory: 0x00007f4308b59a80 | 80 9a b5 08 43 7f 00 00&lt;br/&gt;
RBP=0x00007f43c02d3950 points into unknown readable memory: 0x00007f43c02d3a60 | 60 3a 2d c0 43 7f 00 00&lt;br/&gt;
RSI=0x00007f43c02d2660 points into unknown readable memory: 0x0000000000000000 | 00 00 00 00 00 00 00 00&lt;br/&gt;
RDI=0x0 is nullptr&lt;br/&gt;
R8 =0x00007f43ac1dab90 is pointing to an (unnamed) stub routine&lt;br/&gt;
R9 =0x00007f43ac1dab80 points into unknown readable memory: 0x00000000000000ee | ee 00 00 00 00 00 00 00&lt;br/&gt;
R10=0x00007f43c634c000 points into unknown readable memory: 0x0100050403020100 | 00 01 02 03 04 05 00 01&lt;br/&gt;
R11=0x0 is nullptr&lt;br/&gt;
R12=0x00007f43c02d2660 points into unknown readable memory: 0x0000000000000000 | 00 00 00 00 00 00 00 00&lt;br/&gt;
R13=0x00007f43c02d2620 points into unknown readable memory: 0x0000000000000000 | 00 00 00 00 00 00 00 00&lt;br/&gt;
R14=0x00007f43c02d26a0 points into unknown readable memory: 0x0000000000000001 | 01 00 00 00 00 00 00 00&lt;br/&gt;
R15=0x00007f42505357a0 is a thread&lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
Top of Stack: (sp=0x00007f43c02d25f0)&lt;br/&gt;
0x00007f43c02d25f0:   00007f4308b59a80 00007f43ac1dacc6&lt;br/&gt;
0x00007f43c02d2600:   000000000000000a 0000000e2f853f00&lt;br/&gt;
0x00007f43c02d2610:   00007f4308b59a80 00007f43ac1dacc6&lt;br/&gt;
0x00007f43c02d2620:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2630:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2640:   00007f0000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2650:   0000000000000000 a6e428ab2f853f00&lt;br/&gt;
0x00007f43c02d2660:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2670:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2680:   00007f0000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2690:   0000000000000000 00007f43c51b77de&lt;br/&gt;
0x00007f43c02d26a0:   0000000000000001 0000000000000001&lt;br/&gt;
0x00007f43c02d26b0:   00007f43c02d37b0 00007f43c4a79c10&lt;br/&gt;
0x00007f43c02d26c0:   0000000000000000 00007f4374584ac0&lt;br/&gt;
0x00007f43c02d26d0:   00007f43c02d37cc 00007f43c54a6303&lt;br/&gt;
0x00007f43c02d26e0:   00007f43c02d2720 00007f43c02d2720&lt;br/&gt;
0x00007f43c02d26f0:   00007f43c580a790 0000004d00000000&lt;br/&gt;
0x00007f43c02d2700:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2710:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2720:   00007f4374584ac0 000000000000004d&lt;br/&gt;
0x00007f43c02d2730:   0000000000000060 00007f43c02d0000&lt;br/&gt;
0x00007f43c02d2740:   0000000000000038 00007f43c54c04f8&lt;br/&gt;
0x00007f43c02d2750:   00007f43c02d2830 00007f43c4e9d034&lt;br/&gt;
0x00007f43c02d2760:   00007f43c02d2c4f 0000003000000018&lt;br/&gt;
0x00007f43c02d2770:   000a303030303031 00007f43c02d2780&lt;br/&gt;
0x00007f43c02d2780:   0000000000000000 0000000000000000&lt;br/&gt;
0x00007f43c02d2790:   00007f43c02d2a50 0000000000000001&lt;br/&gt;
0x00007f43c02d27a0:   00007f43c02d4700 000000000000000d&lt;br/&gt;
0x00007f43c02d27b0:   0000000000000002 00007f43c5c6a0a0&lt;br/&gt;
0x00007f43c02d27c0:   ffffffffffffffff 0000000000000000&lt;br/&gt;
0x00007f43c02d27d0:   00007f43c02d3700 00007f43c02d3610&lt;br/&gt;
0x00007f43c02d27e0:   00000000ffffffff 0000003000000010 &lt;br/&gt;
&lt;br/&gt;
Instructions: (pc=0x00007f43c4b81577)&lt;br/&gt;
0x00007f43c4b81477:   8d c0 ec ff ff 4c 89 85 c8 ec ff ff e8 18 29 fd&lt;br/&gt;
0x00007f43c4b81487:   ff 4c 8b 85 c8 ec ff ff 48 8b 8d c0 ec ff ff 84&lt;br/&gt;
0x00007f43c4b81497:   c0 0f 84 3a 02 00 00 80 7d c6 00 0f 84 78 01 00&lt;br/&gt;
0x00007f43c4b814a7:   00 4c 89 f2 4c 89 ee 4c 89 e7 e8 7a 2d fd ff e9&lt;br/&gt;
0x00007f43c4b814b7:   53 fe ff ff 0f 1f 44 00 00 48 8d 05 11 b2 cc 00&lt;br/&gt;
0x00007f43c4b814c7:   48 8b 00 48 85 c0 0f 84 9d 00 00 00 48 8b 48 08&lt;br/&gt;
0x00007f43c4b814d7:   48 39 ca 0f 82 90 00 00 00 48 63 40 14 48 01 c1&lt;br/&gt;
0x00007f43c4b814e7:   48 39 ca 0f 83 1b ff ff ff 4c 89 f2 4c 89 ee 4c&lt;br/&gt;
0x00007f43c4b814f7:   89 e7 e8 92 ce 0c 00 e9 0b fe ff ff 0f 1f 44 00&lt;br/&gt;
0x00007f43c4b81507:   00 48 83 ec 08 ff b5 00 ed ff ff 8b b5 bc ec ff&lt;br/&gt;
0x00007f43c4b81517:   ff 4c 89 ff ff b5 f8 ec ff ff ff b5 f0 ec ff ff&lt;br/&gt;
0x00007f43c4b81527:   ff b5 e8 ec ff ff ff b5 e0 ec ff ff ff b5 d8 ec&lt;br/&gt;
0x00007f43c4b81537:   ff ff ff b5 d0 ec ff ff e8 4c fc ff ff 48 8d 65&lt;br/&gt;
0x00007f43c4b81547:   d8 5b 41 5c 41 5d 41 5e 41 5f 5d c3 0f 1f 44 00&lt;br/&gt;
0x00007f43c4b81557:   00 4c 89 f2 4c 89 ee 4c 89 e7 e8 7a cb 0c 00 e9&lt;br/&gt;
0x00007f43c4b81567:   a3 fd ff ff 0f 1f 44 00 00 48 8b 85 f8 ec ff ff&lt;br/&gt;
0x00007f43c4b81577:   48 8b 78 08 f3 0f 7e 08 48 8d 48 10 48 c7 85 28&lt;br/&gt;
0x00007f43c4b81587:   ed ff ff 00 00 00 00 66 48 0f 6e c1 c6 85 34 ed&lt;br/&gt;
0x00007f43c4b81597:   ff ff 00 66 48 0f 6e ff 66 0f 6c c8 66 0f 6c c7&lt;br/&gt;
0x00007f43c4b815a7:   0f 11 8d 38 ed ff ff 0f 29 85 10 ed ff ff e8 a6&lt;br/&gt;
0x00007f43c4b815b7:   77 f7 ff 48 89 85 20 ed ff ff 48 89 c7 48 85 c0&lt;br/&gt;
0x00007f43c4b815c7:   74 34 80 7f 5d 00 74 2e 48 8b 85 18 ed ff ff 48&lt;br/&gt;
0x00007f43c4b815d7:   8b 97 80 00 00 00 48 39 d0 0f 84 c2 00 00 00 80&lt;br/&gt;
0x00007f43c4b815e7:   7f 5e 03 0f 84 90 00 00 00 48 3b 87 88 00 00 00&lt;br/&gt;
0x00007f43c4b815f7:   0f 84 ab 00 00 00 48 8d 05 f4 3f d0 00 48 39 38&lt;br/&gt;
0x00007f43c4b81607:   0f 84 b6 00 00 00 c7 85 30 ed ff ff 00 00 00 00&lt;br/&gt;
0x00007f43c4b81617:   e9 f2 fc ff ff 0f 1f 40 00 48 8b 75 b0 4c 89 ea&lt;br/&gt;
0x00007f43c4b81627:   4c 89 e7 e8 11 34 fd ff e9 da fc ff ff 0f 1f 40&lt;br/&gt;
0x00007f43c4b81637:   00 0f b6 46 5c 48 8b bd e8 ec ff ff 88 45 a8 48&lt;br/&gt;
0x00007f43c4b81647:   85 ff 0f 84 06 01 00 00 4c 89 f2 4c 89 ee 4c 89&lt;br/&gt;
0x00007f43c4b81657:   85 c0 ec ff ff 48 89 8d c8 ec ff ff e8 28 5a 61&lt;br/&gt;
0x00007f43c4b81667:   00 4c 8b 85 c0 ec ff ff 48 8b 8d c8 ec ff ff e9 &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
Stack slot to memory mapping:&lt;br/&gt;
stack at sp + 0 slots: 0x00007f4308b59a80 is pointing into the stack for thread: 0x00007f42505357a0&lt;br/&gt;
stack at sp + 1 slots: 0x00007f43ac1dacc6 is at begin+137 in a stub&lt;br/&gt;
StubRoutines::call_stub [0x00007f43ac1dac3d, 0x00007f43ac1dad3e] (257 bytes)&lt;br/&gt;
stack at sp + 2 slots: 0x000000000000000a is an unknown value&lt;br/&gt;
stack at sp + 3 slots: 0x0000000e2f853f00 is an unknown value&lt;br/&gt;
stack at sp + 4 slots: 0x00007f4308b59a80 is pointing into the stack for thread: 0x00007f42505357a0&lt;br/&gt;
stack at sp + 5 slots: 0x00007f43ac1dacc6 is at begin+137 in a stub&lt;br/&gt;
StubRoutines::call_stub [0x00007f43ac1dac3d, 0x00007f43ac1dad3e] (257 bytes)&lt;br/&gt;
stack at sp + 6 slots: 0x0 is nullptr&lt;br/&gt;
stack at sp + 7 slots: 0x0 is nullptr&lt;br/&gt;
&lt;br/&gt;
VM_Operation (0x00007f4394adc9f0): DeoptimizeFrame, mode: safepoint, requested by thread 0x00007f43bc2ffde0&lt;br/&gt;
&lt;br/&gt;
</description>
                <environment></environment>
        <key id="5097938">JDK-8305625</key>
            <summary>Stress test crashes with SEGV in Deoptimization::deoptimize_frame_internal(JavaThread*, long*, Deoptimization::DeoptReason)</summary>
                <type id="1" iconUrl="https://bugs.openjdk.org/secure/viewavatar?size=xsmall&amp;avatarId=14703&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://bugs.openjdk.org/images/jbsImages/p2.png">P2</priority>
                        <status id="5" iconUrl="https://bugs.openjdk.org/images/icons/statuses/resolved.png" description="A resolution has been taken, and it is awaiting verification by reporter. From here issues are either reopened, or are closed.">Resolved</status>
                    <statusCategory id="3" key="done" colorName="success"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pchilanomate">Patricio Chilano Mateo</assignee>
                                    <reporter username="lmesnik">Leonid Mesnik</reporter>
                        <labels>
                            <label>deopt</label>
                            <label>loom</label>
                            <label>noreg-hard</label>
                            <label>oracle-triage-21</label>
                    </labels>
                <created>Tue, 4 Apr 2023 18:58:01 -0700</created>
                <updated>Wed, 10 Jul 2024 10:18:06 -0700</updated>
                            <resolved>Mon, 17 Apr 2023 07:43:12 -0700</resolved>
                                    <version>21</version>
                                    <fixVersion>21</fixVersion>
                                    <component>hotspot</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="14574211" author="dukebot" created="Mon, 17 Apr 2023 07:43:05 -0700"  >Changeset: 73609604&lt;br/&gt;
Author:    Patricio Chilano Mateo &amp;lt;&lt;a href=&apos;mailto:pchilanomate@openjdk.org&apos;&gt;pchilanomate@openjdk.org&lt;/a&gt;&amp;gt;&lt;br/&gt;
Date:      2023-04-17 14:40:29 +0000&lt;br/&gt;
URL:       &lt;a href=&quot;https://git.openjdk.org/jdk/commit/7360960454b3116a0724396f25415f2c3bcf8930&quot;&gt;https://git.openjdk.org/jdk/commit/7360960454b3116a0724396f25415f2c3bcf8930&lt;/a&gt;&lt;br/&gt;
</comment>
                            <comment id="14573509" author="rehn" created="Thu, 13 Apr 2023 01:48:00 -0700"  >[~pchilanomate] We could redo the allocation if there is a GC mode is changed before we write anything.&lt;br/&gt;
Anyhow might require a bit of work. So maybe best just the fix the current issue for now.</comment>
                            <comment id="14573476" author="thartmann" created="Wed, 12 Apr 2023 22:25:53 -0700"  >Thanks, I&amp;#39;m moving this to hotspot/runtime because the fix is in runtime owned code.</comment>
                            <comment id="14573418" author="dcubed" created="Wed, 12 Apr 2023 13:04:43 -0700"  >[~thartmann]&lt;br/&gt;
&amp;gt; Just wondering, should we move this to hotspot/jvmti?&lt;br/&gt;
&lt;br/&gt;
Reading thru this bug&amp;#39;s comments, it&amp;#39;s not clear to me that this bug&lt;br/&gt;
belongs in hotspot/jvmti. The issue appears to be related to deoptimization&lt;br/&gt;
and Loom. Deoptimization issues are typically shared between the Compiler&lt;br/&gt;
team and the Runtime team. </comment>
                            <comment id="14573349" author="roboduke" created="Wed, 12 Apr 2023 09:13:54 -0700"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk/pull/13446&quot;&gt;https://git.openjdk.org/jdk/pull/13446&lt;/a&gt;&lt;br/&gt;
Date: 2023-04-12 15:48:53 +0000</comment>
                            <comment id="14573337" author="pchilanomate" created="Wed, 12 Apr 2023 07:59:35 -0700"  >[~rehn] I tested your idea but I found we cannot go back to Java after the allocation because that might safepoint and the chunk could change to GC mode before we start using it. There is a comment about delaying safepoints after the chunk has been allocated.</comment>
                            <comment id="14573081" author="rehn" created="Tue, 11 Apr 2023 07:35:46 -0700"  >Thanks [~pchilanomate]</comment>
                            <comment id="14572986" author="rehn" created="Tue, 11 Apr 2023 01:24:43 -0700"  >Modifying the stack while in VM is dangerous.&lt;br/&gt;
If you are in VM with a pending suspend and do a block in vm, the thread will be suspended but allowed to continue execute in VM.&lt;br/&gt;
The thread will be stopped when trying to enter Java or do Java-a-like operation.&lt;br/&gt;
This means the suspender may be working on the stack.&lt;br/&gt;
&lt;br/&gt;
To get this (freeze) safe it should be done from Java.&lt;br/&gt;
In this case enter VM allocate chunk, return to Java and do the freeze.&lt;br/&gt;
&lt;br/&gt;
This would not be a problem then.&lt;br/&gt;
Hence fixing this problem, but still modifying the stack in VM can still cause bugs if there is a suspend request.&lt;br/&gt;
I don&amp;#39;t see any e.g. TBIVM in this code now, but the code paths spread out.&lt;br/&gt;
&lt;br/&gt;
(This wired situation with stack assumed to be stable while in VM is very old,. Suspending on all transitions breaks the JDWP/JVM TI agent and since it assumes what operations may suspend.)</comment>
                            <comment id="14572973" author="thartmann" created="Tue, 11 Apr 2023 00:36:06 -0700"  >Just wondering, should we move this to hotspot/jvmti?</comment>
                            <comment id="14572969" author="rrich" created="Tue, 11 Apr 2023 00:19:18 -0700"  >I was not planning to take this issue. It would be great if you could.&lt;br/&gt;
</comment>
                            <comment id="14572373" author="pchilanomate" created="Thu, 6 Apr 2023 21:49:58 -0700"  >I attached a simple reproducer. Fails for me every time.&lt;br/&gt;
&lt;br/&gt;
The way other JVMTI operations make sure there are no threads in a transition while the operation is being executed is to use the JvmtiVTMSTransitionDisabler. So using that would be a solution too.&lt;br/&gt;
Now, I see that for this particular operation we are skipping stacks of mounted virtual threads altogether so we don&amp;#39;t really care if they are in a transition. That means that as I mentioned before we could just adjust the check to identify virtual threads, since reading jvmti_vthread() is not enough. So we could check is_vthread_mounted() instead, which returns true until the continuation entry is actually removed from the stack. &lt;br/&gt;
The is_in_VTMS_transition() check I suggested earlier also works. It&amp;#39;s just that it will be more restrictive, because there is a window of time where the continuation has already been unmounted (return from enterSpecial) but the transition bit is still set (the bit is cleared later in afterYield()) so we will skip walking that stack in that case.&lt;br/&gt;
&lt;br/&gt;
[~rrich] [~rehn] were any of you guys planning to take this, otherwise I can assign it to myself.</comment>
                            <comment id="14572270" author="rehn" created="Thu, 6 Apr 2023 06:49:43 -0700"  >&amp;gt;Do you actually mean the `_obj_deopt` suspend flag?&lt;br/&gt;
&lt;br/&gt;
We also have JFR native sampling flag, I think due to the circumstances how and when we freeze it&amp;#39;s not a problem.&lt;br/&gt;
But if we would freeze a thread with that suspend_flag set, we are certainly in some trouble :)&lt;br/&gt;
&lt;br/&gt;
And these two are the only two flags left. (To be removed)</comment>
                            <comment id="14572263" author="rrich" created="Thu, 6 Apr 2023 05:57:42 -0700"  >&amp;gt; &amp;gt; EDIT: I see, after the safepoint for the allocation the target does _not_ check has_special_runtime_exit_condition(&lt;br/&gt;
&amp;gt;&lt;br/&gt;
&amp;gt; That&amp;#39;s what I saying by &amp;quot;pin the thread&amp;quot;, aka make sure stack stays on it if we get suspend flag set.&lt;br/&gt;
&lt;br/&gt;
Right. I do get it now.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; Now disabling may also work, but with pinning on suspend flag we may get more JVM TI working on vthread. &lt;br/&gt;
&lt;br/&gt;
Do you actually mean the `_obj_deopt` suspend flag? If yes then I think&lt;br/&gt;
EscapeBarrier based object deoptimization should be avoided if a vthread is&lt;br/&gt;
mounted. It would require JvmtiDeferredUpdates to be &amp;quot;virtualized&amp;quot;. This doesn&amp;#39;t&lt;br/&gt;
seem to be the case currently. Even setting a local variable does not seem to be&lt;br/&gt;
possible for frames in continuations (see VM_BaseGetOrSetLocal::doit).&lt;br/&gt;
&lt;br/&gt;
But maybe I&amp;#39;m misunderstanding. I haven&amp;#39;t been following the JVMTI-with-VThreads-Story. It does look sufficiently complex.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; Maybe adding a check for jt-&amp;gt;is_in_VTMS_transition() when skipping virtual threads is what is missing. So we skip mounted virtual threads or when we are at transitions.&lt;br/&gt;
&lt;br/&gt;
This would make sense to me.</comment>
                            <comment id="14572071" author="rehn" created="Wed, 5 Apr 2023 12:17:01 -0700"  >&amp;gt;I checked and the fr at the point of crashing has all null values:&lt;br/&gt;
&lt;br/&gt;
I don&amp;#39;t like the API of sender since there is no natural way of saying last/entry frame.&lt;br/&gt;
Now in theory you should always check fp? before using the frame returned.&lt;br/&gt;
&lt;br/&gt;
&amp;gt;EDIT: I see, after the safepoint for the allocation the target does _not_ check has_special_runtime_exit_condition(&lt;br/&gt;
&lt;br/&gt;
That&amp;#39;s what I saying by &amp;quot;pin the thread&amp;quot;, aka make sure stack stays on it if we get suspend flag set.&lt;br/&gt;
Now disabling may also work, but with pinning on suspend flag we may get more JVM TI working on vthread.&lt;br/&gt;
&lt;br/&gt;
Yes, thanks Patricio for digging!</comment>
                            <comment id="14572064" author="pchilanomate" created="Wed, 5 Apr 2023 11:10:45 -0700"  >[~rrich] Right, the actual suspend will be done later on the&amp;#xA0;next transition back to Java.&lt;br/&gt;
&lt;br/&gt;
Maybe adding a check for jt-&amp;gt;is_in_VTMS_transition() when skipping virtual threads is what is missing. So we skip mounted virtual threads or when we are at transitions.</comment>
                            <comment id="14572035" author="rrich" created="Wed, 5 Apr 2023 09:09:29 -0700"  >Thank you Patricio. That&amp;#39;s a nice analysis.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; - The EscapeBarrier requester proceeds to EscapeBarrier::deoptimize_objects_all_threads(). The thread in freeze is seen as a normal thread because the jvmti rebinding is done before freezing. Walks the stack before the thread comes out of the allocation path to change the anchor to the entry frame (FreezeBase::unwind_frames()). &lt;br/&gt;
&lt;br/&gt;
So the target thread is suspended here because of the EscapeBarrier::sync_and_suspend_all() &lt;br/&gt;
&lt;br/&gt;
&amp;gt; - The deoptimization safepoint catches the target thread after the freezing and change of anchor is done, in the JRT_BLOCK_END of the freeze slow path. &lt;br/&gt;
&lt;br/&gt;
But it was suspended above.&lt;br/&gt;
&lt;br/&gt;
EDIT: I see, after the safepoint for the allocation the target does _not_ check has_special_runtime_exit_condition(). It continues and is blocked at JRT_BLOCK_END.&lt;br/&gt;
&lt;br/&gt;
The EscapeBarrier logic does not expect stack changes after sync_and_suspend_all().</comment>
                            <comment id="14572024" author="pchilanomate" created="Wed, 5 Apr 2023 08:46:05 -0700"  >I think a possible explanation could be if we hit the the following case:&lt;br/&gt;
&lt;br/&gt;
- EscapeBarrier::sync_and_suspend_all() sets the _obj_deopt flag for a thread that is inside freeze and the handshake all operation to synchronize with all threads (EscapeBarrierSuspendHandshake) finds that thread blocked in the stack allocation path so it succeeds.&lt;br/&gt;
- The EscapeBarrier requester proceeds to EscapeBarrier::deoptimize_objects_all_threads(). The thread in freeze is seen as a normal thread because the jvmti rebinding is done before freezing. Walks the stack before the thread comes out of the allocation path to change the anchor to the entry frame (FreezeBase::unwind_frames()).&lt;br/&gt;
- Requester finds a possible frame to deopt, that belongs to the vthread, and requests a vm operation to deoptimize it. &lt;br/&gt;
- The deoptimization safepoint catches the target thread after the freezing and change of anchor is done, in the JRT_BLOCK_END of the freeze slow path.&lt;br/&gt;
- Frame is no longer there so we just loop until we get a null frame (is that what will happen if we keep calling sender() ? )&lt;br/&gt;
&lt;br/&gt;
I checked and the anchor field for the thread being deoptimized is correctly set:&lt;br/&gt;
&lt;br/&gt;
_anchor = {_last_Java_sp = 0x7f4308b59640, _last_Java_pc = 0x7f43ac8553eb &amp;quot;\017\037\204&amp;quot;, _last_Java_fp = 0x7f4308b59680}&lt;br/&gt;
&lt;br/&gt;
and the thread is indeed blocked in that JRT_BLOCK_END on the slow path.&lt;br/&gt;
&lt;br/&gt;
The id of the frame requested for deopt is 0x7f4308b59510 which is a lower address than the current _last_Java_sp of that target. So we never find it in that loop:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;while (fr.id() != id) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;fr = fr.sender(&amp;amp;reg_map);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&lt;br/&gt;
I checked and the fr at the point of crashing has all null values:&lt;br/&gt;
&lt;br/&gt;
(gdb) p	fr&lt;br/&gt;
$4 = {{_sp = 0x0, _offset_sp = 0}, _pc = 0x0, _cb = 0x0, _oop_map = 0x0, _deopt_state = frame::not_deoptimized, _on_heap = false, {_fp = 0x0, _offset_fp = 0}, {_unextended_sp = 0x0,&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;_offset_unextended_sp = 0}}&lt;br/&gt;
</comment>
                            <comment id="14572012" author="rrich" created="Wed, 5 Apr 2023 07:39:26 -0700"  >&amp;gt; Without looking into details, the EscapeBarrier mechanism is at odds with virtual threads and is supposed to be disabled completely or partially. &lt;br/&gt;
&lt;br/&gt;
It is partially disabled. E.g. deoptimization is skipped vor vthreads: &lt;a href=&quot;https://github.com/openjdk/jdk/blob/2e59d21e5620e834cb55a69d23a16c44d6ca2393/src/hotspot/share/runtime/escapeBarrier.cpp#L126-L130&quot;&gt;https://github.com/openjdk/jdk/blob/2e59d21e5620e834cb55a69d23a16c44d6ca2393/src/hotspot/share/runtime/escapeBarrier.cpp#L126-L130&lt;/a&gt;</comment>
                            <comment id="14571981" author="rpressler" created="Wed, 5 Apr 2023 06:12:15 -0700"  >Without looking into details, the EscapeBarrier mechanism is at odds with virtual threads and is supposed to be disabled completely or partially. &lt;br/&gt;
&lt;br/&gt;
[~sspitsyn]</comment>
                            <comment id="14571963" author="rehn" created="Wed, 5 Apr 2023 05:06:37 -0700"  >frame fr = thread-&amp;gt;last_frame();                                                                                    &lt;br/&gt;
while (fr.id() != id) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;fr = fr.sender(&amp;amp;reg_map);&lt;br/&gt;
}                                                                                                                   &lt;br/&gt;
deoptimize(thread, fr, reason); &lt;br/&gt;
&lt;br/&gt;
1: I don&amp;#39;t think we can or should freeze if any suspend flag is set, do we consider them?&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Suspend flag should probably pin the continuation.&lt;br/&gt;
&lt;br/&gt;
2: The stack walking should work. It seem like frame::sender can crash if we just keep calling it ? Or something is not correct on stack.&lt;br/&gt;
&lt;br/&gt;
3: Above while seem to be able to loop forever, if not 2 crashes, and it assumes 1 cannot happen. (id must be found?)&lt;br/&gt;
&lt;br/&gt;
I don&amp;#39;t think this related to normal deopt.&lt;br/&gt;
&lt;br/&gt;
[~thartmann][~pchilanomate][~rpressler][~rrich]</comment>
                            <comment id="14571955" author="rehn" created="Wed, 5 Apr 2023 04:33:37 -0700"  >[Switching to thread 66 (LWP 3157029)]&lt;br/&gt;
#0  0x00007f43c58e69bd in syscall () from core.3145843.solibs/lib64/libc.so.6&lt;br/&gt;
#0  0x00007f43c58e69bd in syscall () from core.3145843.solibs/lib64/libc.so.6&lt;br/&gt;
#1  0x00007f43c5423dc3 in futex (op_arg=2057465, futex_op=128, addr=0x7f4374000b74) at open/src/hotspot/os/linux/waitBarrier_linux.cpp:49&lt;br/&gt;
#2  LinuxWaitBarrier::wait (this=0x7f4374000b74, barrier_tag=2057465) at open/src/hotspot/os/linux/waitBarrier_linux.cpp:76&lt;br/&gt;
#3  0x00007f43c52548d6 in WaitBarrierType&amp;lt;LinuxWaitBarrier&amp;gt;::wait (barrier_tag=&amp;lt;optimized out&amp;gt;, this=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/utilities/waitBarrier.hpp:128&lt;br/&gt;
#4  SafepointSynchronize::block (thread=0x7f42505357a0) at open/src/hotspot/share/runtime/safepoint.cpp:718&lt;br/&gt;
#5  0x00007f43c525c26e in SafepointMechanism::process (thread=thread@entry=0x7f42505357a0, allow_suspend=allow_suspend@entry=true, check_async_exception=check_async_exception@entry=false) at open/src/hotspot/share/runtime/safepointMechanism.cpp:148&lt;br/&gt;
#6  0x00007f43c4ddeb44 in SafepointMechanism::process_if_requested (check_async_exception=false, allow_suspend=true, thread=0x7f42505357a0) at open/src/hotspot/share/runtime/safepointMechanism.inline.hpp:83&lt;br/&gt;
#7  ThreadBlockInVMPreprocess&amp;lt;void (JavaThread*)&amp;gt;::~ThreadBlockInVMPreprocess() (this=&amp;lt;synthetic pointer&amp;gt;, __in_chrg=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/runtime/interfaceSupport.inline.hpp:218&lt;br/&gt;
#8  ThreadBlockInVMPreprocess&amp;lt;void (JavaThread*)&amp;gt;::~ThreadBlockInVMPreprocess() (this=&amp;lt;synthetic pointer&amp;gt;, __in_chrg=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/runtime/interfaceSupport.inline.hpp:211&lt;br/&gt;
#9  ThreadBlockInVM::~ThreadBlockInVM (this=&amp;lt;synthetic pointer&amp;gt;, __in_chrg=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/runtime/interfaceSupport.inline.hpp:223&lt;br/&gt;
#10 JavaThread::wait_for_object_deoptimization (this=this@entry=0x7f42505357a0) at open/src/hotspot/share/runtime/javaThread.cpp:1187&lt;br/&gt;
#11 0x00007f43c4ddec54 in JavaThread::handle_special_runtime_exit_condition (this=0x7f42505357a0) at open/src/hotspot/share/runtime/javaThread.cpp:1024&lt;br/&gt;
#12 0x00007f43c4b5c7e0 in SafepointMechanism::process_if_requested_with_exit_check (check_async_exception=true, thread=0x7f42505357a0) at open/src/hotspot/share/runtime/safepointMechanism.inline.hpp:90&lt;br/&gt;
#13 ThreadStateTransition::transition_from_vm (check_asyncs=true, to=_thread_in_Java, thread=0x7f42505357a0) at open/src/hotspot/share/runtime/interfaceSupport.inline.hpp:113&lt;br/&gt;
#14 ThreadInVMfromJava::~ThreadInVMfromJava (this=&amp;lt;synthetic pointer&amp;gt;, __in_chrg=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/runtime/interfaceSupport.inline.hpp:140&lt;br/&gt;
#15 freeze_internal&amp;lt;Config&amp;lt;(oop_kind)0, G1BarrierSet&amp;gt; &amp;gt; (sp=&amp;lt;optimized out&amp;gt;, current=0x7f42505357a0) at open/src/hotspot/share/runtime/continuationFreezeThaw.cpp:1580&lt;br/&gt;
#16 Config&amp;lt;(oop_kind)0, G1BarrierSet&amp;gt;::freeze (sp=&amp;lt;optimized out&amp;gt;, thread=0x7f42505357a0) at open/src/hotspot/share/runtime/continuationFreezeThaw.cpp:267&lt;br/&gt;
#17 freeze&amp;lt;Config&amp;lt;(oop_kind)0, G1BarrierSet&amp;gt; &amp;gt; (current=0x7f42505357a0, sp=&amp;lt;optimized out&amp;gt;) at open/src/hotspot/share/runtime/continuationFreezeThaw.cpp:234&lt;br/&gt;
#18 0x00007f43ac855cd5 in ?? ()&lt;br/&gt;
#19 0x0000000682910dc0 in ?? ()&lt;br/&gt;
#20 0x00007f43aca36a08 in ?? ()&lt;br/&gt;
#21 0x0000000682910ea8 in ?? ()&lt;br/&gt;
#22 0x0000000000000000 in ?? ()&lt;br/&gt;
&lt;br/&gt;
One thread is iterating through heap and therefore using EscapeBarrier::deoptimize_objects_all_threads.&lt;br/&gt;
&lt;br/&gt;
On back-edge of freeze when transitioning back we hit this safepoint and for some reason fp() is null.</comment>
                            <comment id="14571945" author="rehn" created="Wed, 5 Apr 2023 03:49:04 -0700"  >We seem to be deopting during a safepoint and crashing on this line:&lt;br/&gt;
inline address  frame::sender_pc()           const { return *sender_pc_addr(); }&lt;br/&gt;
&lt;br/&gt;
The thread we are working is probably &amp;quot;ForkJoinPool-1-worker-7649&amp;quot;&lt;br/&gt;
Which means:&lt;br/&gt;
sender_pc_addr() == &amp;amp;fp()[1];&lt;br/&gt;
&lt;br/&gt;
RAX=0x0000000000000000&lt;br/&gt;
&lt;br/&gt;
5c: 48 8b 48 08             mov    rcx,QWORD PTR [rax+0x8]&lt;br/&gt;
&lt;br/&gt;
So _fp is not set (0).&lt;br/&gt;
&lt;br/&gt;
Since the JavaThread is afepoint safe it should be walkable.</comment>
                            <comment id="14571930" author="thartmann" created="Wed, 5 Apr 2023 02:30:52 -0700"  >Thanks, Robbin!</comment>
                            <comment id="14571925" author="rehn" created="Wed, 5 Apr 2023 02:01:51 -0700"  >Ok, I&amp;#39;ll have a look.</comment>
                            <comment id="14571894" author="thartmann" created="Tue, 4 Apr 2023 23:46:48 -0700"  >[~rehn] thinks that it could be a regression from &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8304743&quot; title=&quot;Compile_lock and SystemDictionary updates&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8304743&quot;&gt;&lt;strike&gt;JDK-8304743&lt;/strike&gt;&lt;/a&gt;.&lt;br/&gt;
&lt;br/&gt;
Update: Okay, that can&amp;#39;t be because that change is not part of the failing run (which is from 2023-03-20).</comment>
                            <comment id="14571892" author="thartmann" created="Tue, 4 Apr 2023 23:23:15 -0700"  >Just a wild guess but this might be related to &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8300926&quot; title=&quot;Several startup regressions  ~6-70% in 21-b6 all platforms&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8300926&quot;&gt;&lt;strike&gt;JDK-8300926&lt;/strike&gt;&lt;/a&gt; (and maybe even &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8303775&quot; title=&quot;CTW test crashed: SEGV in CompiledMethod::mark_for_deoptimization&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8303775&quot;&gt;&lt;strike&gt;JDK-8303775&lt;/strike&gt;&lt;/a&gt;).</comment>
                            <comment id="14571891" author="chagedorn" created="Tue, 4 Apr 2023 23:22:08 -0700"  >ILW = Crash in deoptimization, only seen once so far, no workaround = HLH = P2</comment>
                    </comments>
                    <attachments>
                            <attachment id="103348" name="Repro.zip" size="2993" author="pchilanomate" created="Thu, 6 Apr 2023 21:46:11 -0700"/>
                            <attachment id="103333" name="gdb.txt" size="236039" author="rehn" created="Wed, 5 Apr 2023 05:07:13 -0700"/>
                            <attachment id="103326" name="hs_err_pid3145843.log" size="338906" author="lmesnik" created="Tue, 4 Apr 2023 19:01:33 -0700"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_11700" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10600" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-fixedBackportedCustomfield">
                        <customfieldname>Fixed</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_11100" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i310tn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_11004" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10006" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Resolved In Build</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="17414"><![CDATA[b19]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10008" key="com.oracle.jira.jira-subcomponent-plugin:oracle-subComponentField">
                        <customfieldname>Subcomponent</customfieldname>
                        <customfieldvalues>
                             <customfieldvalue key="192"><![CDATA[runtime]]></customfieldvalue> 
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10601" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-targetBackportedCustomfield">
                        <customfieldname>Targeted</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>