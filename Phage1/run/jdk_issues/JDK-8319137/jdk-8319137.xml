<!-- 
RSS generated by JIRA (9.12.27#9120027-sha1:edc4490121e366e9e7bd2213d532dbe7e028fc5d) at Tue Sep 30 11:06:51 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>Java Bug System</title>
    <link>https://bugs.openjdk.org</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-us</language>    <build-info>
        <version>9.12.27</version>
        <build-number>9120027</build-number>
        <build-date>02-09-2025</build-date>
    </build-info>


<item>
            <title>[JDK-8319137] release _object in ObjectMonitor dtor to avoid races</title>
                <link>https://bugs.openjdk.org/browse/JDK-8319137</link>
                <project id="10100" key="JDK">JDK</project>
                    <description>The following stress test failed in my jdk-22+21 stress testing run:&lt;br/&gt;
&lt;br/&gt;
StressWrapper_SetNameAtExit.java&lt;br/&gt;
&lt;br/&gt;
which is a wrapper around the following test:&lt;br/&gt;
&lt;br/&gt;
runtime/Thread/SetNameAtExit.java&lt;br/&gt;
&lt;br/&gt;
Here&amp;#39;s a snippet from the log file:&lt;br/&gt;
&lt;br/&gt;
#section:main&lt;br/&gt;
----------messages:(6/341)----------&lt;br/&gt;
command: main -XX:+HeapDumpOnOutOfMemoryError -Xmx128m SetNameAtExit 6646&lt;br/&gt;
reason: User specified action: run main/othervm/timeout=6946 -XX:+HeapDumpOnOutOfMemoryError -Xmx128m SetNameAtExit 6646&lt;br/&gt;
started: Sat Oct 28 04:05:29 EDT 2023&lt;br/&gt;
Mode: othervm [/othervm specified]&lt;br/&gt;
finished: Sat Oct 28 04:48:23 EDT 2023&lt;br/&gt;
elapsed time (seconds): 2574.554&lt;br/&gt;
----------configuration:(0/0)----------&lt;br/&gt;
----------System.out:(18/1156)----------&lt;br/&gt;
About to execute for 6646 seconds.&lt;br/&gt;
#&lt;br/&gt;
# A fatal error has been detected by the Java Runtime Environment:&lt;br/&gt;
#&lt;br/&gt;
#  Internal Error (/System/Volumes/Data/work/shared/bug_hunt/thread_SMR_stress/jdk22_exp.git/open/src/hotspot/share/oops/weakHandle.inline.hpp:38), pid=49774, tid=24579&lt;br/&gt;
#  assert(!is_null()) failed: Must be created&lt;br/&gt;
#&lt;br/&gt;
# JRE version: Java(TM) SE Runtime Environment (22.0) (slowdebug build 22-internal-2023-10-26-1411081.dcubed...)&lt;br/&gt;
# Java VM: Java HotSpot(TM) 64-Bit Server VM (slowdebug 22-internal-2023-10-26-1411081.dcubed..., mixed mode, sharing, tiered, compressed oops, compressed class ptrs, g1 gc, bsd-aarch64)&lt;br/&gt;
# Core dump will be written. Default location: ../core.49774&lt;br/&gt;
#&lt;br/&gt;
# An error report file with more information is saved as:&lt;br/&gt;
# /System/Volumes/Data/work/shared/bug_hunt/thread_SMR_stress/jdk22_exp.git/build/macosx-aarch64-normal-server-slowdebug/test-support/jtreg_open_test_hotspot_jtreg_StressWrapper_SetNameAtExit_java/StressWrapper_SetNameAtExit/hs_err_pid49774.log&lt;br/&gt;
[2565.454s][warning][os] Loading hsdis library failed&lt;br/&gt;
#&lt;br/&gt;
# If you would like to submit a bug report, please visit:&lt;br/&gt;
#   &lt;a href=&quot;https://bugreport.java.com/bugreport/crash.jsp&quot;&gt;https://bugreport.java.com/bugreport/crash.jsp&lt;/a&gt;&lt;br/&gt;
#&lt;br/&gt;
----------System.err:(0/0)----------&lt;br/&gt;
----------rerun:(35/5474)*----------&lt;br/&gt;
&lt;br/&gt;
and here&amp;#39;s the crashing thread&amp;#39;s stack:&lt;br/&gt;
&lt;br/&gt;
---------------  T H R E A D  ---------------&lt;br/&gt;
&lt;br/&gt;
Current thread (0x000000012e811a10):  JavaThread &amp;quot;MainThread&amp;quot;        [_thread_in_Java, id=24579, stack(0x00000001717b4000,0x00000001719b7000) (2060K)]&lt;br/&gt;
&lt;br/&gt;
Stack: [0x00000001717b4000,0x00000001719b7000],  sp=0x00000001719b5d00,  free space=2055k&lt;br/&gt;
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)&lt;br/&gt;
V  [libjvm.dylib+0x128b66c]  VMError::report_and_die(int, char const*, char const*, char*, Thread*, unsigned char*, void*, void*, char const*, int, unsigned long)+0x93c  (weakHandle.inline.hpp:38)&lt;br/&gt;
V  [libjvm.dylib+0x128bd04]  VMError::report_and_die(Thread*, char const*, int, unsigned long, VMErrorType, char const*, char*)+0x0&lt;br/&gt;
V  [libjvm.dylib+0x62cef4]  print_error_for_unit_test(char const*, char const*, char*)+0x0&lt;br/&gt;
V  [libjvm.dylib+0x523da8]  WeakHandle::peek() const+0x58&lt;br/&gt;
V  [libjvm.dylib+0xf2eec4]  ObjectMonitor::object_peek() const+0x3c&lt;br/&gt;
V  [libjvm.dylib+0x117ca24]  ObjectSynchronizer::quick_enter(oopDesc*, JavaThread*, BasicLock*)+0x100&lt;br/&gt;
V  [libjvm.dylib+0x1094314]  SharedRuntime::monitor_enter_helper(oopDesc*, BasicLock*, JavaThread*)+0x34&lt;br/&gt;
V  [libjvm.dylib+0x10944d4]  SharedRuntime::complete_monitor_locking_C(oopDesc*, BasicLock*, JavaThread*)+0xa0&lt;br/&gt;
Java frames: (J=compiled Java code, j=interpreted, Vv=VM code)&lt;br/&gt;
v  ~RuntimeStub::_complete_monitor_locking_Java 0x0000000116ae2494&lt;br/&gt;
J 295% c2 SetNameAtExit.main([Ljava/lang/String;)V (247 bytes) @ 0x0000000116f977fc [0x0000000116f94d00+0x0000000000002afc]&lt;br/&gt;
j  java.lang.invoke.LambdaForm$DMH+0x0000024001002000.invokeStatic(Ljava/lang/Object;Ljava/lang/Object;)V+10 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  java.lang.invoke.LambdaForm$MH+0x0000024001003400.invoke(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;+33 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  java.lang.invoke.Invokers$Holder.invokeExact_MT(Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;+20 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  jdk.internal.reflect.DirectMethodHandleAccessor.invokeImpl(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+55 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  jdk.internal.reflect.DirectMethodHandleAccessor.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+23 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  java.lang.reflect.Method.invoke(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;+102 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  com.sun.javatest.regtest.agent.MainWrapper$MainTask.run()V+134&lt;br/&gt;
j  java.lang.Thread.runWith(Ljava/lang/Object;Ljava/lang/Runnable;)V+5 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
j  java.lang.Thread.run()V+19 &lt;a href=&apos;mailto:java.base@22-internal&apos;&gt;java.base@22-internal&lt;/a&gt;&lt;br/&gt;
v  ~StubRoutines::call_stub 0x00000001169d417c&lt;br/&gt;
Lock stack of current Java thread (top to bottom):&lt;br/&gt;
&amp;lt;empty&amp;gt;&lt;br/&gt;
&lt;br/&gt;
The test failed in a single slowdebug config so in 1 of 9 runs during&lt;br/&gt;
the jdk-22+21 stress testing cycle.</description>
                <environment></environment>
        <key id="5113565">JDK-8319137</key>
            <summary>release _object in ObjectMonitor dtor to avoid races</summary>
                <type id="1" iconUrl="https://bugs.openjdk.org/secure/viewavatar?size=xsmall&amp;avatarId=14703&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://bugs.openjdk.org/images/jbsImages/p2.png">P2</priority>
                        <status id="6" iconUrl="https://bugs.openjdk.org/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="success"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="pchilanomate">Patricio Chilano Mateo</assignee>
                                    <reporter username="dcubed">Daniel Daugherty</reporter>
                        <labels>
                            <label>amazon-interest</label>
                            <label>intermittent</label>
                            <label>jdk21u-fix-request</label>
                            <label>jdk21u-fix-yes</label>
                            <label>sync</label>
                    </labels>
                <created>Mon, 30 Oct 2023 12:17:04 -0700</created>
                <updated>Wed, 21 Feb 2024 18:03:05 -0800</updated>
                            <resolved>Wed, 22 Nov 2023 07:03:02 -0800</resolved>
                                    <version>21</version>
                    <version>22</version>
                                    <fixVersion>22</fixVersion>
                                    <component>hotspot</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>11</watches>
                                                                                                                <comments>
                            <comment id="14633899" author="roboduke" created="Wed, 13 Dec 2023 03:10:02 -0800"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk21u-dev/pull/12&quot;&gt;https://git.openjdk.org/jdk21u-dev/pull/12&lt;/a&gt;&lt;br/&gt;
Date: 2023-12-13 11:02:46 +0000</comment>
                            <comment id="14628994" author="roboduke" created="Mon, 27 Nov 2023 01:20:22 -0800"  >[jdk21u-fix-request] Approval Request from Aleksey Shipil&amp;#xEB;v&lt;br/&gt;
This effectively reverts [&lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt;](&lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302),&quot;&gt;https://bugs.openjdk.org/browse/JDK-8256302),&lt;/a&gt; which introduced race condition in JDK 21. The patch needs a few minor adjustments to match JDK 21. Testing passes.</comment>
                            <comment id="14628853" author="roboduke" created="Fri, 24 Nov 2023 11:33:51 -0800"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk21u/pull/401&quot;&gt;https://git.openjdk.org/jdk21u/pull/401&lt;/a&gt;&lt;br/&gt;
Date: 2023-11-24 12:03:48 +0000</comment>
                            <comment id="14628818" author="shade" created="Fri, 24 Nov 2023 03:25:10 -0800"  >Note for backport sequencing: &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8319896&quot; title=&quot;Remove monitor deflation from final audit&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8319896&quot;&gt;&lt;strike&gt;JDK-8319896&lt;/strike&gt;&lt;/a&gt; needs to be backported first, otherwise the JavaThread::cast in new code would fail when called from final audit. (Edit: or maybe not, I can actually revert to pre-JDK 21 form, and we would not expose JDK 21 to the risk of rewrites right away; let me see...)</comment>
                            <comment id="14628458" author="dukebot" created="Wed, 22 Nov 2023 07:03:00 -0800"  >Changeset: c39d001c&lt;br/&gt;
Author:    Patricio Chilano Mateo &amp;lt;&lt;a href=&apos;mailto:pchilanomate@openjdk.org&apos;&gt;pchilanomate@openjdk.org&lt;/a&gt;&amp;gt;&lt;br/&gt;
Date:      2023-11-22 14:59:47 +0000&lt;br/&gt;
URL:       &lt;a href=&quot;https://git.openjdk.org/jdk/commit/c39d001c7a1ae9eb322a7bb621a03e18c9bf02a1&quot;&gt;https://git.openjdk.org/jdk/commit/c39d001c7a1ae9eb322a7bb621a03e18c9bf02a1&lt;/a&gt;&lt;br/&gt;
</comment>
                            <comment id="14627686" author="pchilanomate" created="Mon, 20 Nov 2023 09:19:43 -0800"  >The PR submitted is an effective backout of &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt; where the race was introduced.</comment>
                            <comment id="14627631" author="roboduke" created="Mon, 20 Nov 2023 07:15:04 -0800"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk/pull/16738&quot;&gt;https://git.openjdk.org/jdk/pull/16738&lt;/a&gt;&lt;br/&gt;
Date: 2023-11-20 14:44:08 +0000</comment>
                            <comment id="14627611" author="stefank" created="Mon, 20 Nov 2023 06:36:31 -0800"  >[~pchilanomate] OK. Let&amp;#39;s go with your patch. Aleksey wanted to proceed with his limited unlink patch and I think your patch will fit better with that. And then we can create a new Bug that covers the rewrite/PoC of the unlinking/deleting of monitor deflation.</comment>
                            <comment id="14627605" author="pchilanomate" created="Mon, 20 Nov 2023 06:20:08 -0800"  >Regarding 8256302 motivation of moving the release of oop storage out of the ObjectMonitor dtor, I&amp;#39;ve been running some micro benchmarks to compare how fast we can deflate. I see that the average time to deflate a monitor(accounting from the time we start walking the monitor list until we finished releasing the memory) goes from as low as 0.17us to as high as 1.5us. This is without introducing safepoints stops in the middle since I just wanted to measure the deflation code. It seems there is a correlation where lower batch sizes result in being closer to the faster deflation rate but I have actually seen this is variable. Regardless, this means that even at the worst deflation rate we should be able to handle any workload outside some artificial benchmark which creates inflated monitors at such fast rate.&lt;br/&gt;
&lt;br/&gt;
I still measured the time it takes to release the oop storage vs the time it takes to free the ObjectMonitor memory to see if it makes sense to split them and remain blocked for the second part but I got mixed results so not sure if that&amp;#39;s worth it.</comment>
                            <comment id="14627604" author="pchilanomate" created="Mon, 20 Nov 2023 06:19:24 -0800"  >[~stefank] Ok, I already have a patch to send for review in case you decide otherwise.</comment>
                            <comment id="14627546" author="stefank" created="Mon, 20 Nov 2023 01:44:03 -0800"  >[~pchilanomate] Axel has a PoC patch (&lt;br/&gt;
&lt;a href=&quot;https://github.com/openjdk/jdk/pull/16412#issuecomment-1818358260)&quot;&gt;https://github.com/openjdk/jdk/pull/16412#issuecomment-1818358260)&lt;/a&gt; that fixes this bug and the &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8319048&quot; title=&quot;Monitor deflation unlink phase prolongs time to safepoint&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8319048&quot;&gt;&lt;strike&gt;JDK-8319048&lt;/strike&gt;&lt;/a&gt;. I&amp;#39;m assigning this bug to him, so that we can work on creating a proper PR for this. If you still want to own this Bug, then ping me.&lt;br/&gt;
</comment>
                            <comment id="14627233" author="eosterlund" created="Fri, 17 Nov 2023 06:45:20 -0800"  >Yes, agreed. Sounds like we have a plan!</comment>
                            <comment id="14627223" author="pchilanomate" created="Fri, 17 Nov 2023 06:20:28 -0800"  >Thanks [~eosterlund]. Okay, then I think the best thing is to move the release back to the ObjectMonitor dtor as it was before &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt;.&lt;br/&gt;
Yes, the old code was already polling for safepoints on each iteration so time to safepoint shouldn&amp;#39;t be a problem. </comment>
                            <comment id="14627213" author="stefank" created="Fri, 17 Nov 2023 06:00:51 -0800"  >[~shade] Is adding incremental polling to the unlink part of the monitor deflation. Erik&amp;#39;s suggestion is to add similar polling to the deletion loop (IIUC). If we end up adding polling for the deletion loop we should consider if we need a flag or not to determine the number of monitors to delete between each poll. If we don&amp;#39;t need a flag here, maybe we don&amp;#39;t need it for the unlink phase either?. Just some food for thought.</comment>
                            <comment id="14627210" author="coleenp" created="Fri, 17 Nov 2023 05:44:23 -0800"  >I couldn&amp;#39;t really tell from the numbers posted in &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt; whether moving the WeakHandle release was really a performance improvement, and I thought from reading it that _not_ polling for safepoint in between each ObjectMonitor destructor call was the cause of the performance improvement.  If that&amp;#39;s the case, the code could poll for safepoint every N iterations of deleting ObjectMonitors, where N is something you can pick based on one of these tests in the original bug that seemed to show the most difference.&lt;br/&gt;
&lt;br/&gt;
Releasing the WeakHandle in the destructor is where it really belongs unless there&amp;#39;s a complelling performance reason not to do that.</comment>
                            <comment id="14627209" author="coleenp" created="Fri, 17 Nov 2023 05:39:54 -0800"  >Thanks, also there&amp;#39;s a comment why for CLD creation races that we need to clear the weak handle OopStorage.  I added it to not upset the GC barrier gods.</comment>
                            <comment id="14627206" author="eosterlund" created="Fri, 17 Nov 2023 05:32:14 -0800"  >[~pchilanomate] No, I think we should honour the current protocol of clearing oops before handing them back to OopStorage, which means that if we release the WeakHandle in the destructor of an ObjectMonitor, we simply have to be in_vm when deleting the ObjectMonitor. But isn&amp;#39;t that a time to safepoint problem? No, not if we delete with incremental polling in the loop; then there will be no time to safepoint problem.</comment>
                            <comment id="14627040" author="pchilanomate" created="Thu, 16 Nov 2023 15:50:39 -0800"  >[~eosterlund] Sorry, just to clarify, are you saying we could have WeakHandle::release(OopStorage* storage) only do storage-&amp;gt;release(_obj);? And not bother clearing the oop?</comment>
                            <comment id="14626979" author="coleenp" created="Thu, 16 Nov 2023 10:12:06 -0800"  >&amp;gt; &amp;gt; The current API effectively allows the WH to be deallocated whilst it is still in use!&lt;br/&gt;
Right.  The WeakHandle and OopHandle API make no promises or claims that they are ok wrt concurrency.  It&amp;#39;s assumed that when you release the {OopWeak}Handle that it&amp;#39;s no longer in use.</comment>
                            <comment id="14624118" author="pchilanomate" created="Mon, 6 Nov 2023 09:26:14 -0800"  >Ok, that&amp;#39;s what we did prior to &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt; so we might need to go back to just releasing the storage when we delete the monitor. I think we don&amp;#39;t need to be in a safepoint unsafe state to do that so we can remain blocked and keep that loop where we delete the monitors as is. The problem with being in a blocked state was clearing the handle (that&amp;#39;s why we moved that call in 8256302 to ObjectMonitor::deflate_monitor()) but if we don&amp;#39;t need to do that we are good.</comment>
                            <comment id="14624108" author="eosterlund" created="Mon, 6 Nov 2023 08:51:25 -0800"  >I thought we could release it in the OM dtor, which hopefully we are not racing with.</comment>
                            <comment id="14624084" author="pchilanomate" created="Mon, 6 Nov 2023 07:36:53 -0800"  >But I think the problem here is the race between releasing the oop storage space and trying to read from it, even if we don&amp;#39;t clear the handle, because the memory could be freed already by the time we do the load (I see this cleanup is done by the ServiceThread, i.e not at a safepoint). Or if we let the GC always clear it, will it also release the oop storage space and will this be done at a safepoint?</comment>
                            <comment id="14623860" author="eosterlund" created="Sun, 5 Nov 2023 21:39:38 -0800"  >I think the main reason the handle is cleared is just history. This used to be a strong oop, but we would run deflation as part of safepoint cleanup to remove as many of these strong roots as possible before the GC could run, which in practice would give it sort of weak ish semantics but not really. The deflation code would clear the strong oop or it would be kept alive by the GC. The oop was placed in an OopHandle, meaning it was still strong, and it worked similarly. I think I might have migrated it to use weak handles as weak semantics was really what the strong + deflate before safepoint operation code was trying to achieve. And I think that when I did that, I should probably have removed the explicit clearing, but didn&#8217;t realize it would cause any trouble either. But yeah I don&#8217;t think we need to do any explicit clearing from deflation any longer since we moved to weak semantics for these roots.</comment>
                            <comment id="14623849" author="dholmes" created="Sun, 5 Nov 2023 20:49:20 -0800"  >&amp;gt; I guess the current design was meant to avoid that overhead in the GC and just rely on the user to do the right thing. &lt;br/&gt;
&lt;br/&gt;
But the user can&amp;#39;t do the &amp;quot;right thing&amp;quot; here. When you allow this type of direct clearing then the accessing code and the clearing code must have a protocol to ensure the handle is never accessed after being cleared.You would need an additional piece of state indicating the handle is valid, which would have to be checked atomically with respect to acting on the handle - i.e. heavyweight locking.&lt;br/&gt;
&lt;br/&gt;
I&amp;#39;m unclear if the current situation is an oversight in the original changes (which were done in 2 parts: first switch to oopStorage, then remove TSM so we actually delete monitors). Or whether we have since changed some assumptions/expectations that previously made it correct? Perhaps [~eosterlund] can comment? I am suspecting that the original design first moved the OM&amp;#39;s to a place they could no longer be accessed, and then deleted them, thus freeing the oopStorage and the weakhandle.</comment>
                            <comment id="14623711" author="pchilanomate" created="Fri, 3 Nov 2023 12:00:39 -0700"  >&amp;gt; The unavoidable usage races are safe if only the GC can do the clearing (which would require a safepoint)&lt;br/&gt;
I guess the current design was meant to avoid that overhead in the GC and just rely on the user to do the right thing. This behavior is actually not  unique to weakHandle, the same issue exists when using OopHandle. If a thread calls release() on an OopHandle and another thread concurrently tries to load/store to that OopHandle the load/store could be executed on already freed memory.</comment>
                            <comment id="14623517" author="dholmes" created="Thu, 2 Nov 2023 20:02:20 -0700"  >Assuming there are no accesses after the referrent is cleared kind of defeats the whole purpose of the API.&lt;br/&gt;
&lt;br/&gt;
// A WeakHandle is a pointer to an oop that is stored in an OopStorage that is&lt;br/&gt;
// processed weakly by GC.  The runtime structures that point to the oop must&lt;br/&gt;
// either peek or resolve the oop, the latter will keep the oop alive for&lt;br/&gt;
// the GC cycle.  The runtime structures that reference the oop must test&lt;br/&gt;
// if the value is null.  If it is null, it has been cleaned out by GC.&lt;br/&gt;
// This is the vm version of jweak but has different GC lifetimes and policies,&lt;br/&gt;
// depending on the type.&lt;br/&gt;
&lt;br/&gt;
but I think the flaw here is that we should not be manually releasing a weakHandle as we do in monitor deflation. The weakHandle is supposed to be cleared by the GC. The unavoidable usage races are safe if only the GC can do the clearing (which would require a safepoint). So I think this is a misuse of this API.</comment>
                            <comment id="14623385" author="pchilanomate" created="Thu, 2 Nov 2023 06:57:42 -0700"  >&amp;gt; If I comment that assert the test actually crashes with SIGSEGV instead.&lt;br/&gt;
Edit: The SIGSEGV crash was not the one I wanted to trigger. This was just a dereference of nullptr now that the assert was removed. I forgot that the call to os::naked_short_nanosleep() makes the compiler reload _obj when we come back. I moved the artificial delay to WeakHandle::peek() instead and used a local to simulate this scenario of reading and verifying _obj is not null but then crashing on the load. But at least for this test it doesn&amp;#39;t crash. The race is still there though it&amp;#39;s just that we need to hit the case where the memory for the oop storage is actually freed by the OopStorage backend for the bug to be visible. I think this will only happen if the block where this address we are releasing lies is completely empty.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; Okay then it seems to me that weakHandle is a fundamentally broken API. The whole point is that the obj is supposed to be reclaimable whilst we still have a weakHandle for it. So releasing the obj should not break the weakHandle as the weakHandle in then supposed to be able to report the obj is now null.&lt;br/&gt;
&amp;gt;&lt;br/&gt;
Looking closer at the API I&amp;#39;m not sure why we have the assert in peek/resolve instead of a check. We do the check for peek/resolve for the OopHandle class. But in any case the check won&amp;#39;t fix the race. We can always check and see that _obj is not null and then the deflater release the storage right before making the load.&lt;br/&gt;
&lt;br/&gt;
&amp;gt; The current API effectively allows the WH to be deallocated whilst it is still in use!&lt;br/&gt;
Yes, but I don&amp;#39;t see how we can prevent that without locking. I guess the API just assumes release() is done at a time where there won&amp;#39;t be any concurrent accesses. And given the asserts in peek/resolve is also assuming there actually won&amp;#39;t be any future accesses.</comment>
                            <comment id="14623155" author="dholmes" created="Wed, 1 Nov 2023 21:37:17 -0700"  >Okay then it seems to me that weakHandle is a fundamentally broken API. The whole point is that the obj is supposed to be reclaimable whilst we still have a weakHandle for it. So releasing the obj should not break the weakHandle as the weakHandle in then supposed to be able to report the obj is now null. The current API effectively allows the WH to be deallocated whilst it is still in use! Or maybe the issue is with the OopStorage mechanism itself - a weak handle needs a way to say to OopStorage &amp;quot;Here&amp;#39;s something that was a pointer to an oop, can you tell me if it is still valid and if so return it and keep it alive for a while&amp;quot;. ??</comment>
                            <comment id="14623150" author="pchilanomate" created="Wed, 1 Nov 2023 21:16:34 -0700"  >&amp;gt; Do we really have a race here or is the expectation that we should just return null and the assertion is getting in the way?&lt;br/&gt;
Yes, we still have a race because we can always see that _obj is not null but right before making the load the address could be freed because the deflater released the oop storage. If I comment that assert the test actually crashes with SIGSEGV instead.</comment>
                            <comment id="14623130" author="dholmes" created="Wed, 1 Nov 2023 17:17:16 -0700"  >&amp;gt; So peek() can return that the oop value pointed to by _obj is null, but _obj itself has to be != null.&lt;br/&gt;
&lt;br/&gt;
Okay the weakHandle code needs a little improvement in that it doesn&amp;#39;t distinguish between the WH never being set versus already having been released. The assertion message  &amp;quot;Must be created&amp;quot; is misleading in the current case. I also think the API is flawed in that peek/resolve should not assert the way they do, but should simply return null if the object has already been released.&lt;br/&gt;
&lt;br/&gt;
Do we really have a race here or is the expectation that we should  just return null and the assertion is getting in the way?</comment>
                            <comment id="14623124" author="pchilanomate" created="Wed, 1 Nov 2023 16:11:45 -0700"  >So peek() can return that the oop value pointed to by _obj is null, but _obj itself has to be != null.&lt;br/&gt;
&lt;br/&gt;
The issue can be easily reproduced by running SetNameAtExit.java (and pretty much every test from what I see) with the options: &amp;quot;-XX:+UnlockDiagnosticVMOptions -XX:GuaranteedAsyncDeflationInterval=10 -XX:TieredStopAtLevel=3 -XX:LockingMode=0&amp;quot; and adding os::naked_short_nanosleep(1) in ObjectMonitor::object_peek() between the is_null() check and the peek() call.&lt;br/&gt;
&lt;br/&gt;
The problem is the race I mentioned above between a thread calling ObjectMonitor::object_peek() and the deflater thread releasing the oop storage for that weak handle in ObjectMonitor::deflate_monitor(). I see this bug was introduced by &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8256302&quot; title=&quot;releasing oopStorage when deflating allows for faster deleting&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8256302&quot;&gt;&lt;strike&gt;JDK-8256302&lt;/strike&gt;&lt;/a&gt; which moved the release of the oop storage from ~ObjectMonitor() to ObjectMonitor::deflate_monitor().&lt;br/&gt;
&lt;br/&gt;
I don&amp;#39;t see why we need to do object_peek() in quick_enter() though to identify the deflation case. If the monitor is deflated the owner change will just fail. But I see there are other usages of ObjectMonitor::object_peek() so I need to verify if those are safe and if not if we can get rid of them.</comment>
                            <comment id="14622582" author="dholmes" created="Tue, 31 Oct 2023 23:45:49 -0700"  >But peek() is allowed to return null, so I don&amp;#39;t see how the assertion inside peek is valid.</comment>
                            <comment id="14622576" author="pchilanomate" created="Tue, 31 Oct 2023 22:27:16 -0700"  >I think this is a race with the deflation thread. So in ObjectSynchronizer::quick_enter()-&amp;gt;ObjectMonitor::object_peek(), between checking _object.is_null() and calling _object.peek() (which also calls is_null()) the deflation thread could run and deflate the monitor releasing the oop storage for _object.&lt;br/&gt;
I&amp;#39;m guessing that we would only see this issue in a slowdebug build though, otherwise that repeated null check for _obj should be optimized out by the compiler. This sounds familiar in nature to &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8303086&quot; title=&quot;SIGSEGV in JavaThread::is_interp_only_mode()&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8303086&quot;&gt;&lt;strike&gt;JDK-8303086&lt;/strike&gt;&lt;/a&gt; where the issue was also reproducible only in slowdebug mode due to this repeated load and check.&lt;br/&gt;
Although even if the _obj is not read twice we might load from a slot that has already been released, so the race is still there. I&amp;#39;ll try tomorrow to see if I can reproduce it.</comment>
                            <comment id="14622566" author="dholmes" created="Tue, 31 Oct 2023 18:28:23 -0700"  >inline oop WeakHandle::resolve() const {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;assert(!is_null(), &amp;quot;Must be created&amp;quot;);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return NativeAccess&amp;lt;ON_PHANTOM_OOP_REF&amp;gt;::oop_load(_obj);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
inline oop WeakHandle::peek() const {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;assert(!is_null(), &amp;quot;Must be created&amp;quot;);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return NativeAccess&amp;lt;ON_PHANTOM_OOP_REF | AS_NO_KEEPALIVE&amp;gt;::oop_load(_obj);&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
Isn&amp;#39;t the whole point of a weakHandle the fact that the referent may be gone because the weakHandle does not keep it alive? If so those asserts seem bogus to me.</comment>
                            <comment id="14622565" author="dholmes" created="Tue, 31 Oct 2023 18:18:55 -0700"  >Is this another lockStack bug?</comment>
                            <comment id="14622495" author="mseledtsov" created="Tue, 31 Oct 2023 11:10:08 -0700"  >ILW = HLH = P2</comment>
                            <comment id="14622126" author="dcubed" created="Mon, 30 Oct 2023 12:21:01 -0700"  >Here&amp;#39;s the logs from my jdk-22+21 stress run sighting on macos-aarch64:&lt;br/&gt;
&lt;br/&gt;
$ unzip -l jdk-22+21_macosx-aarch64.8319137.zip&lt;br/&gt;
Archive:  jdk-22+21_macosx-aarch64.8319137.zip&lt;br/&gt;
&amp;nbsp;&amp;nbsp;Length      Date    Time    Name&lt;br/&gt;
---------  ---------- -----   ----&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;660587  10-28-2023 04:48   jdk-22+21_2/failures.macosx-aarch64/hs_err_pid49774.log&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;23200  10-28-2023 04:48   jdk-22+21_2/failures.macosx-aarch64/StressWrapper_SetNameAtExit.jtr.slowdebug&lt;br/&gt;
---------                     -------&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;683787                     2 files</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10200">
                    <name>Backport</name>
                                            <outwardlinks description="backported by">
                                        <issuelink>
            <issuekey id="5118018">JDK-8322942</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="5122146">JDK-8326440</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10000">
                    <name>Blocks</name>
                                                                <inwardlinks description="is blocked by">
                                        <issuelink>
            <issuekey id="5114511">JDK-8319896</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                            <issuelinktype id="10003">
                    <name>Relates</name>
                                            <outwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="5034473">JDK-8256302</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                    </issuelinks>
                <attachments>
                            <attachment id="106957" name="jdk-22+21_macosx-aarch64.8319137.zip" size="70526" author="dcubed" created="Mon, 30 Oct 2023 12:21:02 -0700"/>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                <customfield id="customfield_10000" key="com.atlassian.jira.plugin.system.customfieldtypes:multiselect">
                        <customfieldname>CPU</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="19000"><![CDATA[x86_64]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_11700" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10600" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-fixedBackportedCustomfield">
                        <customfieldname>Fixed</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_10005" key="com.atlassian.jira.plugin.system.customfieldtypes:multiselect">
                        <customfieldname>OS</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="17023"><![CDATA[linux]]></customfieldvalue>
    
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                            <customfield id="customfield_11100" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i33ohn:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_11004" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10006" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Resolved In Build</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="17357"><![CDATA[b26]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10008" key="com.oracle.jira.jira-subcomponent-plugin:oracle-subComponentField">
                        <customfieldname>Subcomponent</customfieldname>
                        <customfieldvalues>
                             <customfieldvalue key="192"><![CDATA[runtime]]></customfieldvalue> 
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10601" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-targetBackportedCustomfield">
                        <customfieldname>Targeted</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10100" key="com.atlassian.jira.plugin.system.customfieldtypes:radiobuttons">
                        <customfieldname>Verification</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="17000"><![CDATA[Verified]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                </customfields>
    </item>
</channel>
</rss>