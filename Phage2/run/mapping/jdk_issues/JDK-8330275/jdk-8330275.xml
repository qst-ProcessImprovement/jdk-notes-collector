<!-- 
RSS generated by JIRA (9.12.27#9120027-sha1:edc4490121e366e9e7bd2213d532dbe7e028fc5d) at Tue Sep 30 12:18:10 UTC 2025

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary append 'field=key&field=summary' to the URL of your request.
-->
<rss version="0.92" >
<channel>
    <title>Java Bug System</title>
    <link>https://bugs.openjdk.org</link>
    <description>This file is an XML representation of an issue</description>
    <language>en-us</language>    <build-info>
        <version>9.12.27</version>
        <build-number>9120027</build-number>
        <build-date>02-09-2025</build-date>
    </build-info>


<item>
            <title>[JDK-8330275] Crash in XMark::follow_array</title>
                <link>https://bugs.openjdk.org/browse/JDK-8330275</link>
                <project id="10100" key="JDK">JDK</project>
                    <description>TL;DR:&lt;br/&gt;
&lt;br/&gt;
On Arm64, with a heap &amp;gt; 1TB and on a machine with 48 bit address space, XAddressOffsetBits can be 45. This can cause followup crashes during marking because code implicitly expects XAddressOffsetBits &amp;lt;= 44.&lt;br/&gt;
&lt;br/&gt;
Details:&lt;br/&gt;
&lt;br/&gt;
We have multiple reports of crashes in ZGC (in both generational and non-generational mode) running on Java 21.&lt;br/&gt;
&lt;br/&gt;
Non-generational mode crash:&lt;br/&gt;
&lt;br/&gt;
Current thread (0x0000ffff9809cfc0):  WorkerThread &amp;quot;XWorker#13&amp;quot;     [id=176319, stack(0x0000ffff0e9ca000,0x0000ffff0ebc8000) (2040K)]&lt;br/&gt;
&lt;br/&gt;
Stack: [0x0000ffff0e9ca000,0x0000ffff0ebc8000],  sp=0x0000ffff0ebc0550,  free space=2009k&lt;br/&gt;
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)&lt;br/&gt;
V  [libjvm.so+0xeabf5c]  XMark::follow_array(unsigned long, unsigned long, bool) [clone .part.0]+0x6c&lt;br/&gt;
V  [libjvm.so+0xead76c]  XMark::work_without_timeout(XMarkContext*)+0xac&lt;br/&gt;
V  [libjvm.so+0xeae378]  XMark::work(unsigned long)+0xb8&lt;br/&gt;
V  [libjvm.so+0xed2148]  XTask::Task::work(unsigned int)+0x28&lt;br/&gt;
V  [libjvm.so+0xe931ec]  WorkerThread::run()+0xac&lt;br/&gt;
V  [libjvm.so+0xde927c]  Thread::call_run()+0xbc&lt;br/&gt;
V  [libjvm.so+0xbe3c3c]  thread_native_entry(Thread*)+0xdc&lt;br/&gt;
C  [libc.so.6+0x82a38]  start_thread+0x2d4&lt;br/&gt;
&lt;br/&gt;
siginfo: si_signo: 11 (SIGSEGV), si_code: 2 (SEGV_ACCERR), si_addr: 0x000022a2379b4000&lt;br/&gt;
&lt;br/&gt;
-----------------------------------&lt;br/&gt;
&lt;br/&gt;
Generational mode crash:&lt;br/&gt;
&lt;br/&gt;
Current thread (0x0000ffff941315e0):  WorkerThread &amp;quot;ZWorkerYoung#4&amp;quot; [id=87563, stack(0x0000fffea1d22000,0x0000fffea1f20000) (2040K)]&lt;br/&gt;
&lt;br/&gt;
Stack: [0x0000fffea1d22000,0x0000fffea1f20000],  sp=0x0000fffea1f18350,  free space=2008k&lt;br/&gt;
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)&lt;br/&gt;
V  [libjvm.so+0xf08858]  mark_barrier_on_oop_array(zpointer volatile*, unsigned long, bool, bool)+0x48&lt;br/&gt;
V  [libjvm.so+0xf0aed8]  ZMark::drain(ZMarkContext*)+0xd8&lt;br/&gt;
V  [libjvm.so+0xf0b070]  ZMark::follow_work(bool)+0xfc&lt;br/&gt;
V  [libjvm.so+0xf35214]  ZRememberedScanMarkFollowTask::work_inner()+0xb4&lt;br/&gt;
V  [libjvm.so+0xf35064]  ZRememberedScanMarkFollowTask::work()+0x24&lt;br/&gt;
V  [libjvm.so+0xe931ec]  WorkerThread::run()+0xac&lt;br/&gt;
V  [libjvm.so+0xde927c]  Thread::call_run()+0xbc&lt;br/&gt;
V  [libjvm.so+0xbe3c3c]  thread_native_entry(Thread*)+0xdc&lt;br/&gt;
C  [libc.so.6+0x82a38]  start_thread+0x2d4&lt;br/&gt;
&lt;br/&gt;
siginfo: si_signo: 11 (SIGSEGV), si_code: 2 (SEGV_ACCERR), si_addr: 0x0000229851cd4000&lt;br/&gt;
&lt;br/&gt;
---------------------------------------&lt;br/&gt;
&lt;br/&gt;
With fastdebug build, it results in assertion failure:&lt;br/&gt;
&lt;br/&gt;
# &lt;br/&gt;
# A fatal error has been detected by the Java Runtime Environment:&lt;br/&gt;
# &lt;br/&gt;
#  Internal Error (/builddir/build/BUILD/java-21-openjdk-21.0.2.0.13-1.el7_9.aarch64/jdk-21.0.2+13/src/hotspot/share/gc/x/xBitField.hpp:76), pid=1517706, tid=1517826&lt;br/&gt;
#  assert(((ContainerType)value &amp;amp; (FieldMask &amp;lt;&amp;lt; ValueShift)) == (ContainerType)value) failed: Invalid value&lt;br/&gt;
#&lt;br/&gt;
# JRE version: OpenJDK Runtime Environment (Red_Hat-21.0.2.0.13-1) (21.0.2+13) (fastdebug build 21.0.2+13-LTS)&lt;br/&gt;
# Java VM: OpenJDK 64-Bit Server VM (Red_Hat-21.0.2.0.13-1) (fastdebug 21.0.2+13-LTS, mixed mode, tiered, compressed class ptrs, z gc, linux-aarch64)&lt;br/&gt;
# Problematic frame:&lt;br/&gt;
# V  [libjvm.so+0x195a8bc]  XMark::push_partial_array(unsigned long, unsigned long, bool)+0x24c&lt;br/&gt;
&lt;br/&gt;
Current thread (0x0000ffff940bb320):  WorkerThread &amp;quot;XWorker#30&amp;quot;     [id=1517826, stack(0x0000ffff084ce000,0x0000ffff086cc000) (2040K)]&lt;br/&gt;
&amp;nbsp;&lt;br/&gt;
Stack: [0x0000ffff084ce000,0x0000ffff086cc000],  sp=0x0000ffff086c44c0,  free space=2009k&lt;br/&gt;
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)&lt;br/&gt;
V  [libjvm.so+0x195a8bc]  XMark::push_partial_array(unsigned long, unsigned long, bool)+0x24c  (xBitField.hpp:76)&lt;br/&gt;
V  [libjvm.so+0x195b034]  XMark::follow_large_array(unsigned long, unsigned long, bool)+0x110&lt;br/&gt;
V  [libjvm.so+0x195b740]  XMark::mark_and_follow(XMarkContext*, XMarkStackEntry)+0x300&lt;br/&gt;
V  [libjvm.so+0x195bf6c]  XMark::work_without_timeout(XMarkContext*)+0xcc&lt;br/&gt;
V  [libjvm.so+0x195c2e8]  XMark::work(unsigned long)+0x164&lt;br/&gt;
V  [libjvm.so+0x1998bf8]  XTask::Task::work(unsigned int)+0x28&lt;br/&gt;
V  [libjvm.so+0x19213a0]  WorkerThread::run()+0xac&lt;br/&gt;
V  [libjvm.so+0x17ea604]  Thread::call_run()+0xb0&lt;br/&gt;
V  [libjvm.so+0x141dc68]  thread_native_entry(Thread*)+0x138&lt;br/&gt;
C  [libc.so.6+0x82a38]  start_thread+0x2d4&lt;br/&gt;
&lt;br/&gt;
-----------------------------------&lt;br/&gt;
Some other command line flags used are:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;-Xmx1200G -Xms1200G -XX:+UseLargePages -XX:+UseTransparentHugePages -XX:SoftMaxHeapSize=840G -XX:+AlwaysPreTouch&lt;br/&gt;
&lt;br/&gt;
Stack traces indicate the problem happens during marking of partial arrays.&lt;br/&gt;
Looking at the the assertion failure in the debug build, it appears the &amp;quot;value&amp;quot; being encoded has extra bits set than the expected.&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;static ContainerType encode(ValueType value) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;assert(((ContainerType)value &amp;amp; (FieldMask &amp;lt;&amp;lt; ValueShift)) == (ContainerType)value, &amp;quot;Invalid value&amp;quot;);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return ((ContainerType)value &amp;gt;&amp;gt; ValueShift) &amp;lt;&amp;lt; FieldShift;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&lt;br/&gt;
The &amp;quot;value&amp;quot; parameter is the address of the partial array being pushed to the mark stack in XMark::push_partial_array():&lt;br/&gt;
&lt;br/&gt;
void XMark::push_partial_array(uintptr_t addr, size_t size, bool finalizable) {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;...&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const uintptr_t offset = XAddress::offset(addr) &amp;gt;&amp;gt; XMarkPartialArrayMinSizeShift;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const uintptr_t length = size / oopSize;&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const XMarkStackEntry entry(offset, length, finalizable);&lt;br/&gt;
&amp;nbsp;&amp;nbsp;...&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
XAddress::offset(value) returns (value &amp;amp; XAddressOffsetMask).&lt;br/&gt;
&lt;br/&gt;
XAddressOffsetMask is a platform dependent value calculated in XAddress::initialize() as:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;XAddressOffsetBits = XPlatformAddressOffsetBits();&lt;br/&gt;
&amp;nbsp;&amp;nbsp;XAddressOffsetMask = (((uintptr_t)1 &amp;lt;&amp;lt; XAddressOffsetBits) - 1) &amp;lt;&amp;lt; XAddressOffsetShift; &lt;br/&gt;
&lt;br/&gt;
XPlatformAddressOffsetBits() for aarch64 in this case returns 45. See the calculations below:&lt;br/&gt;
&lt;br/&gt;
size_t XPlatformAddressOffsetBits() {&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const static size_t valid_max_address_offset_bits = probe_valid_max_address_bit() + 1;  // 47 + 1 = 48  (value of probe_valid_max_address_bit() is present in error logs)&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t max_address_offset_bits = valid_max_address_offset_bits - 3; // 48 - 3 = 45&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t min_address_offset_bits = max_address_offset_bits - 2; // 45 - 2 = 43&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t address_offset = round_up_power_of_2(MaxHeapSize * XVirtualToPhysicalRatio); // MaxHeapSize = 1200GB, XVirtualToPhysicalRatio = 16 so address_offset = 2^45&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t address_offset_bits = log2i_exact(address_offset); // address_offset_bits = 45&lt;br/&gt;
&amp;nbsp;&amp;nbsp;return clamp(address_offset_bits, min_address_offset_bits, max_address_offset_bits); // returns min(max(address_offset_bits, min_address_offset_bits), max_address_offset_bits) = 45&lt;br/&gt;
}&lt;br/&gt;
&lt;br/&gt;
So,&lt;br/&gt;
&amp;nbsp;&amp;nbsp;XAddressOffsetBits = 45&lt;br/&gt;
&amp;nbsp;&amp;nbsp;XAddressOffsetShift = 0&lt;br/&gt;
&amp;nbsp;&amp;nbsp;which implies XAddressOffsetMask = 0x0000_1FFF_FFFF_FFFF&lt;br/&gt;
&lt;br/&gt;
So XAddress::offset(addr) returns the least significant 45 bits of the address.&lt;br/&gt;
XMarkPartialArrayMinSizeShift is 12, therefore &amp;quot;offset&amp;quot; in XMark::push_partial_array() is set to last 33 bits of the address.&lt;br/&gt;
&lt;br/&gt;
But the encoding of the offset in XMarkStackEntry indicates only 32-bits are used, which means we are discarding the bit 33:&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;typedef XBitField&amp;lt;uint64_t, size_t,    32, 32&amp;gt; field_partial_array_offset;&lt;br/&gt;
&lt;br/&gt;
If the partial array address happens to have bit 45 set then its encoding would result in losing the MSB, and this can trigger the assertion we are seeing with the debug build.&lt;br/&gt;
&lt;br/&gt;
It can also explain the other crashes seen with release build. Those crashes happen when a partial array is being marked.&lt;br/&gt;
Because the partial array is encoded incorrectly (MSB is lost), when the offset is decoded later, it returns invalid address.&lt;br/&gt;
Trying to deference it results in a crash.&lt;br/&gt;
</description>
                <environment></environment>
        <key id="5126909">JDK-8330275</key>
            <summary>Crash in XMark::follow_array</summary>
                <type id="1" iconUrl="https://bugs.openjdk.org/secure/viewavatar?size=xsmall&amp;avatarId=14703&amp;avatarType=issuetype">Bug</type>
                                            <priority id="2" iconUrl="https://bugs.openjdk.org/images/jbsImages/p2.png">P2</priority>
                        <status id="6" iconUrl="https://bugs.openjdk.org/images/icons/statuses/closed.png" description="The issue is considered finished, the resolution is correct. Issues which are closed can be reopened.">Closed</status>
                    <statusCategory id="3" key="done" colorName="success"/>
                                    <resolution id="1">Fixed</resolution>
                                        <assignee username="asmehra">Ashutosh Mehra</assignee>
                                    <reporter username="asmehra">Ashutosh Mehra</reporter>
                        <labels>
                            <label>amazon-interest</label>
                            <label>jdk21u-fix-request</label>
                            <label>jdk21u-fix-yes</label>
                            <label>jdk22u-fix-SQE-ok</label>
                            <label>jdk22u-fix-request</label>
                            <label>jdk22u-fix-yes</label>
                            <label>zgc</label>
                    </labels>
                <created>Mon, 15 Apr 2024 09:38:14 -0700</created>
                <updated>Fri, 1 Nov 2024 08:26:03 -0700</updated>
                            <resolved>Wed, 8 May 2024 13:27:15 -0700</resolved>
                                    <version>21.0.2</version>
                    <version>22</version>
                    <version>23</version>
                                    <fixVersion>23</fixVersion>
                                    <component>hotspot</component>
                        <due></due>
                            <votes>0</votes>
                                    <watches>8</watches>
                                                                                                                <comments>
                            <comment id="14676886" author="roboduke" created="Tue, 28 May 2024 10:33:40 -0700"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk22u/pull/226&quot;&gt;https://git.openjdk.org/jdk22u/pull/226&lt;/a&gt;&lt;br/&gt;
Date: 2024-05-28 17:29:19 +0000</comment>
                            <comment id="14676885" author="roboduke" created="Tue, 28 May 2024 10:31:42 -0700"  >[jdk22u-fix-request] Approval Request from Ashutosh Mehra&lt;br/&gt;
This fixes a bug in ZGC that can result in crash when running with huge heap size. It only affects aarch64.</comment>
                            <comment id="14676849" author="roboduke" created="Tue, 28 May 2024 08:10:43 -0700"  >[jdk21u-fix-request] Approval Request from Ashutosh Mehra&lt;br/&gt;
This fixes a bug in ZGC that can result in crash when running with huge heap size. It only affects aarch64.</comment>
                            <comment id="14676846" author="roboduke" created="Tue, 28 May 2024 08:05:38 -0700"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk21u-dev/pull/612&quot;&gt;https://git.openjdk.org/jdk21u-dev/pull/612&lt;/a&gt;&lt;br/&gt;
Date: 2024-05-28 14:59:47 +0000</comment>
                            <comment id="14672082" author="dukebot" created="Wed, 8 May 2024 13:27:13 -0700"  >Changeset: 42b1d858&lt;br/&gt;
Author:    Ashutosh Mehra &amp;lt;&lt;a href=&apos;mailto:asmehra@openjdk.org&apos;&gt;asmehra@openjdk.org&lt;/a&gt;&amp;gt;&lt;br/&gt;
Date:      2024-05-08 20:26:02 +0000&lt;br/&gt;
URL:       &lt;a href=&quot;https://git.openjdk.org/jdk/commit/42b1d858d15fd06de9ce41b08b430b12724652e9&quot;&gt;https://git.openjdk.org/jdk/commit/42b1d858d15fd06de9ce41b08b430b12724652e9&lt;/a&gt;&lt;br/&gt;
</comment>
                            <comment id="14667864" author="stefank" created="Thu, 25 Apr 2024 00:18:55 -0700"  >&amp;gt; I have run test/hotspot/jtreg/gc/z and test/hotspot/jtreg/gc/x against my patch to check for any regressions. But they contain very small number of tests. Are there any other tests for zgc that I should be running as well? &lt;br/&gt;
&lt;br/&gt;
Our test infra runs almost all tests with the GC specified. You can probably get a decent amount of test by running the various open tiers with the given GC flags:&lt;br/&gt;
&lt;br/&gt;
Non-generational ZGC:&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier1 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier2 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier3 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
&lt;br/&gt;
Generational ZGC:&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier1 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-generational-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier2 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-generational-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
make -C ../build/fastdebug/ test TEST=tier3 JTREG=&amp;quot;EXTRA_PROBLEM_LISTS=ProblemList-generational-zgc.txt;JAVA_OPTIONS=-XX:+UseZGC -XX:+ZVerifyOops;JOBS=4&amp;quot;&lt;br/&gt;
&lt;br/&gt;
I set lowered the number of jobs with JOBS=4, so that the OOM killer don&amp;#39;t kick in if too many JVMs are running at the same time. </comment>
                            <comment id="14667809" author="roboduke" created="Wed, 24 Apr 2024 13:28:49 -0700"  >A pull request was submitted for review.&lt;br/&gt;
URL: &lt;a href=&quot;https://git.openjdk.org/jdk/pull/18941&quot;&gt;https://git.openjdk.org/jdk/pull/18941&lt;/a&gt;&lt;br/&gt;
Date: 2024-04-24 20:22:52 +0000</comment>
                            <comment id="14667748" author="JIRAUSER20510" created="Wed, 24 Apr 2024 08:46:30 -0700"  >[~stefank] I have run test/hotspot/jtreg/gc/z and test/hotspot/jtreg/gc/x against my patch to check for any regressions. But they contain very small number of tests. Are there any other tests for zgc that I should be running as well?</comment>
                            <comment id="14666310" author="stuefe" created="Thu, 18 Apr 2024 11:15:35 -0700"  >I was planning, at some point, to have a generic function to probe the end of the address space, and then fix this number in the os:: namespace somewhere. We already have this for the lower address space end - I added os::vm_min_address() last year for all our platforms - and I would like to have a complementing os::vm_max_address(). We need it e.g. for ASLR-aware class space reservation (os::reserve_memory_inbetween()) and I planned to use this function for other areas too. I hardcoded the end address space to 128TB or something in that function, which is not great.&lt;br/&gt;
&lt;br/&gt;
This does not have to be in this RFE, of course. &lt;br/&gt;
&lt;br/&gt;
But if we are really worried about reducing the number of msyncs and mmaps at startup, we should eventually come to a global function that does this job once and stores the result globally for all subsystems to use.</comment>
                            <comment id="14666248" author="JIRAUSER20510" created="Thu, 18 Apr 2024 06:13:50 -0700"  >I should mention that different hardwares employ different strategies to probe:&lt;br/&gt;
1. x86 has hardcoded the address bits to 44&lt;br/&gt;
2. aarch64 and riscv probe the bit 47 and go down to bit 37&lt;br/&gt;
3. ppc tries to reduce probing by starting with bit 45 and go up if it is addressable upto bit 60, or else go down to 36&lt;br/&gt;
&lt;br/&gt;
So all arch except x86 potentially suffer from this issue. Its another matter if it would ever happen in the wild.&lt;br/&gt;
&lt;br/&gt;
Given that these arch impose different restrictions on addressable memory, and the bound our implementation imposes&lt;br/&gt;
on the usable bits (currently 44-bits) is likely to be stricter than the arch imposed limitation, I suggest we go other way round,&lt;br/&gt;
that is, we start from 44-bits and then go down if it is not addressable.&lt;br/&gt;
Also, I have similar opinion to Stefan that probing in the memory area we cannot use doesn&amp;#39;t look useful.&lt;br/&gt;
&lt;br/&gt;
I am also inclined to adjust XMarkPartialArrayMinSizeShift dynamically depending on the maximum address offset bits such that it is always &amp;gt;= 12 &lt;br/&gt;
i.e. &lt;br/&gt;
XMaxAddressBits = 44&lt;br/&gt;
XMarkPartialArrayOffsetBits = 32&lt;br/&gt;
XMarkDefaultPartialArrayMinSizeShift = 12&lt;br/&gt;
XMarkPartialArrayMinSizeShift = MAX(XMaxAddressBits-XMarkPartialArrayOffsetBits, XMarkDefaultPartialArrayMinSizeShift)&lt;br/&gt;
&lt;br/&gt;
so that if at all we increase XMaxAddressBits in future beyond 44 bits, XMarkPartialArrayMinSizeShift would be set properly.&lt;br/&gt;
In case dynamic probe returns address offset bits &amp;lt; 44, we would continue to use the default value of 12.</comment>
                            <comment id="14666197" author="stuefe" created="Thu, 18 Apr 2024 03:47:55 -0700"  >The probing API could contain hardware knowledge. E.g., probe the 52 bit only on Linux and only if page size is 64k.&lt;br/&gt;
&lt;br/&gt;
But we could keep it as it is for now, that works too.</comment>
                            <comment id="14666190" author="stefank" created="Thu, 18 Apr 2024 02:58:52 -0700"  >It makes sense, but it adds probing in a memory area that we know that we can&amp;#39;t use. That seems somewhat useless, albeit maybe more future proof if we decide to increase the offset bits in Generational ZGC, so maybe it is OK.&lt;br/&gt;
&lt;br/&gt;
However, note my point above about the finalizable bit, so it should probably be:&lt;br/&gt;
&lt;br/&gt;
- keep probe_address_space as it is. Arguably it should even be expanded, to 52 bits.&lt;br/&gt;
- then, take off that value by the number of needed meta bits (3)&lt;br/&gt;
- and finally, cap that result to 44 bits. &lt;br/&gt;
</comment>
                            <comment id="14666189" author="stefank" created="Thu, 18 Apr 2024 02:49:51 -0700"  >&amp;gt; 2) the fact that we need space in user-addressable space for four meta bits (and StefanK said that ErikOe said that, apparently, the fourth bit - the finalizable one - needs to be in user-addressable space too) &lt;br/&gt;
&lt;br/&gt;
This is a misunderstanding. The finalizable bit does *NOT* need to be in the user-addressable space.</comment>
                            <comment id="14666084" author="stuefe" created="Wed, 17 Apr 2024 13:33:23 -0700"  >I think we deal with three different limits here:&lt;br/&gt;
1) the extend of the user address space. that can be, on arm64 linux, either 39, 48 or 52 bits.&lt;br/&gt;
2) the fact that we need space in user-addressable space for four meta bits (and StefanK said that ErikOe said that, apparently, the fourth bit - the finalizable one - needs to be in user-addressable space too)&lt;br/&gt;
3) the fact that we expect the offset to be not higher than 32 + 12 bits, so 44 bits.&lt;br/&gt;
&lt;br/&gt;
Therefore I would encode that clearly:&lt;br/&gt;
- keep probe_address_space as it is. Arguably it should even be expanded, to 52 bits.&lt;br/&gt;
- then, take off that value by the number of needed meta bits (4) &lt;br/&gt;
- and finally, cap that result to 44 bits.&lt;br/&gt;
&lt;br/&gt;
Does that make sense?</comment>
                            <comment id="14666082" author="JIRAUSER20510" created="Wed, 17 Apr 2024 13:17:31 -0700"  >[~stefank] since the generational mode doesn&amp;#39;t need the 3-bits for metadata, I think we should get rid of this calculation in ZPlatformAddressOffsetBits():&lt;br/&gt;
&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t max_address_offset_bits = valid_max_address_offset_bits - 3;&lt;br/&gt;
&lt;br/&gt;
and instead set max_address_offset_bits to probe_valid_max_address_bit() + 1&lt;br/&gt;
That implies for generational mode DEFAULT_MAX_ADDRESS_BIT should be 43.&lt;br/&gt;
Does that make sense?&lt;br/&gt;
</comment>
                            <comment id="14666028" author="stefank" created="Wed, 17 Apr 2024 08:57:39 -0700"  >[~asmehra] I think it sounds like a good fix. It would also be good to capture the essence of this discussion in a comment explaining why the value 46 has been chosen.</comment>
                            <comment id="14666022" author="JIRAUSER20510" created="Wed, 17 Apr 2024 08:21:53 -0700"  >[~stefank] I initially thought that -3 is a mistake and it should be -4 but Thomas rightly pointed to me (and you reiterated that as well) that the finalizable bit is not used to form an address. &lt;br/&gt;
So if -3 is right, then the only other option is to reduce DEFAULT_MAX_ADDRESS_BIT to 46.&lt;br/&gt;
At this moment I think reverting the max_address_offset_bits back to 44 bits seems to be the safest approach to fix it. Do you agree with this, or do you have other alternatives in mind?</comment>
                            <comment id="14665879" author="stuefe" created="Wed, 17 Apr 2024 02:32:17 -0700"  >On Arm64, one can have a 52-bit address space even, I think, when running with 64k pages. Not sure how prevalent this is though, I kind of have the feeling that 64k page kernels are being phased out.&lt;br/&gt;
&lt;br/&gt;
One advantage of extending the address space would be that we can enjoy the 16x factor between virtual and physical memory for heaps&amp;gt;1TB too. As it is now, starting at 1TB, the ratio shrinks. </comment>
                            <comment id="14665862" author="stefank" created="Wed, 17 Apr 2024 02:00:48 -0700"  >FWIW, I once started to rewrite Generational ZGC to be able to handle larger heaps (because it doesn&amp;#39;t use multi-mapping and the bits above). I never completed that exercise mostly because it wasn&amp;#39;t a high priority to get the heaps beyond 16 TB. It would probably be worth looking into this again.</comment>
                            <comment id="14665858" author="stefank" created="Wed, 17 Apr 2024 01:49:39 -0700"  >I think this is the problematic line:&lt;br/&gt;
&amp;nbsp;&amp;nbsp;const size_t max_address_offset_bits = valid_max_address_offset_bits - 3; // 48 - 3 = 45 &lt;br/&gt;
&lt;br/&gt;
I think the &amp;quot;- 3&amp;quot; part is wrong (and probably should be a named constant).&lt;br/&gt;
&lt;br/&gt;
If you compare that to the ascii art of the address bits:&lt;br/&gt;
&lt;a href=&quot;https://github.com/openjdk/jdk/blob/7744b0046af4dbacb7068ae819d8a973cfbf8e40/src/hotspot/cpu/aarch64/gc/x/xGlobals_aarch64.cpp#L137&quot;&gt;https://github.com/openjdk/jdk/blob/7744b0046af4dbacb7068ae819d8a973cfbf8e40/src/hotspot/cpu/aarch64/gc/x/xGlobals_aarch64.cpp#L137&lt;/a&gt;&lt;br/&gt;
```&lt;br/&gt;
//   6               4  4  4 4&lt;br/&gt;
//   3               8  7  4 3                                               0&lt;br/&gt;
//  +------------------+----+-------------------------------------------------+&lt;br/&gt;
//  |00000000 00000000 |1111|1111 11111111 11111111 11111111 11111111 11111111|&lt;br/&gt;
//  +------------------+----+-------------------------------------------------+&lt;br/&gt;
//  |                  |    |&lt;br/&gt;
//  |                  |    * 43-0 Object Offset (44-bits, 16TB address space)&lt;br/&gt;
//  |                  |&lt;br/&gt;
//  |                  * 47-44 Metadata Bits (4-bits)  0001 = Marked0      (Address view 16-32TB)&lt;br/&gt;
//  |                                                  0010 = Marked1      (Address view 32-48TB)&lt;br/&gt;
//  |                                                  0100 = Remapped     (Address view 64-80TB)&lt;br/&gt;
//  |                                                  1000 = Finalizable  (Address view N/A)&lt;br/&gt;
//  |&lt;br/&gt;
//  * 63-48 Fixed (16-bits, always zero)&lt;br/&gt;
```&lt;br/&gt;
&lt;br/&gt;
You can see that we use 4 bits for the metadata, so we need to remove 4 and not 3, right?&lt;br/&gt;
&lt;br/&gt;
Edit: No, 3 is right. It refers to the number of views that we put in the addressable memory range. The finalizable bit is always removed before we access the memory. The problematic part seems more to be that on these machines we manage to map memory between 128T and 256T, which doesn&amp;#39;t happen on x86 machines.</comment>
                            <comment id="14665678" author="JIRAUSER20510" created="Tue, 16 Apr 2024 08:56:32 -0700"  >[~stefank] Can you please chime in here if you agree with restricting max_address_offset_bits to 44 bits for aarch64? I think the DEFAULT_MAX_ADDRESS_BIT should be updated to 46 in order to restrict max_address_offset_bits to 44 bits.</comment>
                            <comment id="14665485" author="stuefe" created="Mon, 15 Apr 2024 23:39:31 -0700"  >[~asmehra] I just thought it would be a pity not to use the full freedom of placing the heap in a 48-bit address space. By restricting ourselves to 44 bits for the offset, we&amp;#39;d lose half the available address space.&lt;br/&gt;
&lt;br/&gt;
That said, your idea of restricting to 44 bits is probably easier and safer. Especially since nobody has machines like this to test regularly.</comment>
                            <comment id="14665344" author="JIRAUSER20510" created="Mon, 15 Apr 2024 20:46:33 -0700"  >Interestingly aarch64 also had same values for&amp;#xA0;max_address_offset_bits and&amp;#xA0;min_address_offset_bits as x86 when zGC support was added for aarch64. See&amp;#xA0;&lt;a href=&quot;https://github.com/openjdk/jdk/commit/51eeaf9cb521092c0f99fd73331e2e65a3b02b95&quot;&gt;https://github.com/openjdk/jdk/commit/51eeaf9cb521092c0f99fd73331e2e65a3b02b95&lt;/a&gt;&lt;br/&gt;
Then later it changed to dynamic probing for&amp;#xA0;&lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8252500&quot;&gt;https://bugs.openjdk.org/browse/JDK-8252500&lt;/a&gt;. So this could probably be a regression introduced by &lt;a href=&quot;https://bugs.openjdk.org/browse/JDK-8252500&quot; title=&quot;ZGC on aarch64: Unable to allocate heap for certain Linux kernel configurations&quot; class=&quot;issue-link&quot; data-issue-key=&quot;JDK-8252500&quot;&gt;&lt;strike&gt;JDK-8252500&lt;/strike&gt;&lt;/a&gt;.</comment>
                            <comment id="14665278" author="JIRAUSER20510" created="Mon, 15 Apr 2024 11:25:14 -0700"  >Comparing aarch64 with x86 for the calculation of the address bits, x86 hardcodes the max_address_offset_bits as 44.&lt;br/&gt;
So should the calculation of max_address_offset_bits for aarch64 return 44-bits as well?&lt;br/&gt;
Another solution suggested by [~stuefe] is to change XMarkPartialArrayMinSizeShift to 13 bits which can also address this problem.</comment>
                    </comments>
                <issuelinks>
                            <issuelinktype id="10200">
                    <name>Backport</name>
                                            <outwardlinks description="backported by">
                                        <issuelink>
            <issuekey id="5130512">JDK-8333111</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="5130696">JDK-8333279</issuekey>
        </issuelink>
            <issuelink>
            <issuekey id="5142928">JDK-8343443</issuekey>
        </issuelink>
                            </outwardlinks>
                                                        </issuelinktype>
                            <issuelinktype id="10003">
                    <name>Relates</name>
                                                                <inwardlinks description="relates to">
                                        <issuelink>
            <issuekey id="5130492">JDK-8333093</issuekey>
        </issuelink>
                            </inwardlinks>
                                    </issuelinktype>
                    </issuelinks>
                <attachments>
                    </attachments>
                <subtasks>
                    </subtasks>
                <customfields>
                                                                            <customfield id="customfield_11700" key="com.atlassian.jira.plugins.jira-development-integration-plugin:devsummary">
                        <customfieldname>Development</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10600" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-fixedBackportedCustomfield">
                        <customfieldname>Fixed</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                                                                                                                                                                                                                                                    <customfield id="customfield_11100" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
                        <customfieldname>Rank</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>0|i35wsz:</customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                <customfield id="customfield_11004" key="com.pyxis.greenhopper.jira:gh-global-rank">
                        <customfieldname>Rank (Obsolete)</customfieldname>
                        <customfieldvalues>
                            <customfieldvalue>9223372036854775807</customfieldvalue>
                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10006" key="com.atlassian.jira.plugin.system.customfieldtypes:select">
                        <customfieldname>Resolved In Build</customfieldname>
                        <customfieldvalues>
                                <customfieldvalue key="17415"><![CDATA[b22]]></customfieldvalue>

                        </customfieldvalues>
                    </customfield>
                                                                                            <customfield id="customfield_10008" key="com.oracle.jira.jira-subcomponent-plugin:oracle-subComponentField">
                        <customfieldname>Subcomponent</customfieldname>
                        <customfieldvalues>
                             <customfieldvalue key="209"><![CDATA[gc]]></customfieldvalue> 
                        </customfieldvalues>
                    </customfield>
                                                                                                                        <customfield id="customfield_10601" key="com.oracle.jira.javabugsystem-jira-plugin:jbs-targetBackportedCustomfield">
                        <customfieldname>Targeted</customfieldname>
                        <customfieldvalues>
                            
                        </customfieldvalues>
                    </customfield>
                                                                                                                                                    </customfields>
    </item>
</channel>
</rss>